### Kafka

####  Kafka 是什么？主要应⽤场景有哪些？

Kafka是一个**分布式流式处理平台**。这到底是什么意思呢？

流平台具有三个关键功能：

1. **消息队列：**发布和订阅消息流，这个功能类似于消息队列，这也是Kafka也被归类为消息队列的原因。
2. **容错的持久方式存储记录消息流**：Kafka会把消息持久化到磁盘，有效避免了消息丢失的风险。
3. **流式处理平台：**在消息发布的时候进行处理，Kafka提供了一个完整的流式处理类库。

##### 两大应用场景

- 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
- 数据处理：构建实时的流数据处理程序来转换或处理数据流。

#### 和其他消息队列相⽐,Kafka的优势在哪⾥？

我们现在经常提到Kafka的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它给RocketMQ、RabbitMQ对比。我觉得Kafka相比其他消息队列主要的优势如下：

- **极致的性能：**基于Scala和Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
- **生态系统兼容性无可匹敌：**Kafka与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

实际上在早期的时候，Kafka并不是一个合格的消息队列，早期的Kafka在消息队列领域就像是一个衣衫褴楼的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和Linkedln最早开发Kafka用于处理海量的日志有很大关系，哈哈哈，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。

随着后续的发展，这些短板都被 Kafka 逐步修复完善，所以，**Kafka 作为消息队列不可靠这个说法已经过时。**

#### 队列模型了解吗？Kafka 的消息模型知道吗？

##### 队列模型：早期的消息模型

![image-20210427130304664](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427130304664.png)

**使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。**比如：我们生产者发送100条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）

###### 队列模型存在的问题：

假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完成的消息内容。
这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。

##### 发布-订阅模型:Kafka 消息模型

> 发布订阅模式主要为了解决队列模式中存在的问题。

![image-20210427131044542](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427131044542.png)

发布订阅模型（Pub-Sub）使用**主题（Topic）**作为消息通信载体，类似于**广播模式**；发布者发布一条消息，该消息通过主题传递给所有的订阅者，**在一条消息广播之后才订阅的用户则是收不到该条消息的**。

**在发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布-订阅模型在功能层面上是可以兼容队列模型的。**

**Kafka采用的就是发布-订阅模型。**

> `RocketMQ `的消息模型和 Kafka 基本是完全⼀样的。唯⼀的区别是 Kafka 中没有队列这个
>
> 概念，与之对应的是 Partition（分区）。

#### 什么是Producer、Consumer、Broker、Topic、Partition？
Kafka 将生产者发布的消息发送到**Topic（主题）**中，需要这些消息的消费者可以订阅这些**Topic（主题）**，如下图所示：

![image-20210427134842830](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427134842830.png)

上面这张图为我们引出了，Kafka比较重要的几个概念：

- **Producer（生产者）：**产生消息的一方。
- **Consumer（消费者）：**消费消息的一方。
- **Broker（代理）：**可以看作是一个独立的Kafka实例。多个Kafka Broker 组成一个Kafka Cluster。

每个`Boker`中又包含了`Topic`以及`Partition`这两个重要的概念。

- **Topic（主题）**：Producer 将消息发送到特定的主题，Consumer 通过订阅特定的Topic（主题）来消费消息。
- **Partition（分区）：**Partition 属于Topic的一部分。一个Topic 可以有多个Partition，并且同一Topic 下的Partition可以分布在不同的Broker上，这也就表明一个Topic 可以横跨多个Broker。这正如我上面所画的图一样。

**Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。**

#### Kafka 的多副本机制了解吗？带来了什么好处？

​		还有一点我觉得比较重要的是Kafka为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做leader的家伙，其他副本称为follower。我们发送的消息会被发送到leader副本，然后follower 副本才能从leader副本中拉取消息进行同步。

> 生产者和消费者只与leader 副本交互。你可以理解为其他副本只是leader副本的拷贝，它们的存在只是为了保证消息存储的安全性。当leader副本发生故障时会从follower中选举出一个leader，但是follower中如果有和leader 同步程度达不到要求的参加不了leader的竞选。

##### Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？
- Kafka 通过给特定Topic 指定多个Partition，而各个Partition可以分布在不同的Broker上，这样便能提供比较好的并发能力（负载均衡）。
- Partition 可以指定对应的Replica数，这也极大地提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。

#### Zookeeper 在 Kafka 中的作⽤知道吗？

`ZooKeeper`主要为Kafka提供元数据的管理的功能。

从图中我们可以看出，Zookeeper 主要为Kafka做了下面这些事情：

1. **Broker 注册：**在Zookeeper 上会有一个**专门用来进行Broker服务器列表记录**的节点。每个Broker 在启动时，都会到Zookeeper 上进行注册，即到/brokers/ids下创建属于自己的节点。每个Broker就会将自己的IP地址和端口等信息记录到该节点中去
2. **Topic 注册：**在Kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper 在维护。比如我创建了一个名字为my-topic的主题并且它有两个分区，对应到z0okeeper中会创建这些文件夹：/brokers/topics/my-topic/Partitions/0、/brokers/topics/my-topic/Partitions/1
3. **负载均衡：**上面也说过了Kafka 通过给特定Topic指定多个Partition，而各个Partition可以分布在不同的Broker上，这样便能提供比较好的并发能力。对于同一个Topic的不同Partition，Kafka会尽力将这些Partition分布到不同的Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker的Partition里面。当Consumer消费的时候，Zookeeper可以根据当前的Partition 数量以及 Consumer 数量来实现动态负载均衡。

#### Kafka 如何保证消息的消费顺序？

我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了2个消息，这2个消息对应的操作分别对应的数据库操作是：更改用户会员等级、根据会员等级计算订单价格。假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。

我们知道Kafka中Partition（分区）是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的Partition（分区）又存在于Topic（主题）这个概念中，并且我们可以给特定Topic 指定多个Partition。

`Kafka Topic Partitions Layout`

![image-20210427141954573](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427141954573.png)

每次添加消息到Partition（分区）的时候都会采用尾加法，如上图所示。Kafka只能为我们保证Partition（分区）中的消息有序，而不能保证 Topic（主题）中的Partition（分区）的有序。

> 消息在被追加到Partition（分区）的时候都会分配一个特定的偏移量（offset）。Kafka通过偏移量（offset）来保证消息在分区内的顺序性。

所以，我们就有一种很简单的保证消息消费顺序的方法：**1个Topic 只对应一个Partition**。这样当然可以解决问题，但是破坏了Kafka的设计初衷。

Kafka中发送1条消息的时候，可以指定topic，partition，key，data（数据）4个参数。如果你发送消息的时候指定了Partition的话，所有消息都会被发送到指定的Partition。并且，同一个key的消息可以保证只发送到同一个partition，这个我们可以采用表/对象的id来作为key。

总结一下，对于如何保证 Kafka中消息消费的顺序，有了下面两种方法：

1. 1个Topic只对应一个Partition。
2. （推荐）发送消息的时候指定key/Partition。

当然不仅仅只有上面两种方法，上面两种方法是我觉得比较好理解的，

#### Kafka 如何保证消息不丢失

##### ⽣产者丢失消息的情况

生产者（Producer）调用`send `方法发送消息之后，消息可能因为网络问题并没有发送过去。

所以，我们不能默认在调用`send` 方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是Kafka 生产者（Producer）使用`send` 方法发送消息实际上是异步的操作，我们可以通过`get()`方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：

![image-20210427142518836](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427142518836.png)

但是不推荐这么做！可以采用为其添加回调函数的行是，示例代码如下：

![image-20210427142616287](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427142616287.png)

如果发送失败，我们检查发送失败的原因之后重新发送即可。

**另外这⾥推荐为 `Producer` 的`retries `（重试次数）设置⼀个⽐较合理的值，⼀般是 3 ，但是为了保证消息不丢失的话⼀般会设置⽐较⼤⼀点。设置完成之后，当出现⽹络问题之后能够⾃动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太⼩的话重试的效果就不明显了，⽹络波动⼀次你3次⼀下⼦就重试完了。**

##### 消费者丢失消息的情况

我们知道消息在被追加到`Partition`（分区）的时候都会分配一个特定的偏移量（`offset`）。偏移量（`offset`）表示` Consumer` 当前消费到的`Partition`（分区）的所在的位置。`Kafka` 通过偏移量（`offset`）可以保证消息在分区内的顺序性。

![image-20210427142856430](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427142856430.png)

当消费者拉取到了分区的某个消息之后，消费者会自动提交了`offset`。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是`offset`却被自动提交了。

**解决办法也比较粗暴，我们手动关闭自动提交offset，每次在真正消费完消息之后之后再自己手动提交offset。**但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。

##### Kafka 弄丢了消息

我们知道Kafka为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做leader的家伙，其他副本称为follower。我们发送的消息会被发送到leader 副本，然后follower副本才能从leader副本中拉取消息进行同步。生产者和消费者只与leader副本交互。你可以理解为其他副本只是leader副本的拷贝，它们的存在只是为了保证消息存储的安全性。

**试想一种情况：假如 leader 副本所在的broker 突然挂掉，那么就要从follower副本重新选出一个leader，但是leader的数据还有一些没有被 follower副本的同步的话，就会造成消息丢失。**

**设置 acks = all**

解决办法就是我们设置**acks=all**。acks 是Kafka 生产者（Producer）很重要的一个参数。
acks的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。当我们配置**acks=all** 则代表**所有副本都要接收到该消息之后该消息才算真正成功被发送。**

**设置 `replication.factor` >= 3**

为了保证 leader 副本能有follower副本能同步消息，我们一般会为topic 设置 **replication.factor>=3**。这样就可以保证每个分区（partition）至少有3个副本。虽然造成了数据冗余，但是带来了数据的安全性。

##### 设置 `min.insync.replicas` > 1

一般情况下我们还需要设置 `**min.insync.replicas`>1**，这样配置代表消息至少要被写入到2个副本才算是被成功发送。`**min.insync.replicas`**的默认值为1，在实际生产中应尽量避免默认值但是，为了保证整个Kafka 服务的高可用性，你需要确保 **`replication.factor`>`min.insync.replicas`**。为什么呢？设想一下加入两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **`replication.factor`=`min.insync.replicas` +1**。

设置**`unclean.leader.election.enable`=false**

我们最开始也说了我们发送的消息会被发送到leader 副本，然后 follower 副本才能从leader副本中拉取消息进行同步。多个follower副本之间的消息同步情况不一样，当我们配置了**`unclean.leader.election.enable`=false**的话，当leader 副本发生故障时就不会从follower副本中和leader 同步程度达不到要求的副本中选择出leader，这样降低了消息丢失的可能性。

#### 如何保证消息不被重复消费？（如何保证消息消费时的幂等性）

##### 重读消费问题

首先，比如 `RabbitMQ`、`RocketMQ`、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。

Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，当我们直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset。等重启之后，少数消息就会再次消费一次。

##### 幂等性

幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，**不能出错**。

##### 如何保证

其实还是得结合业务来思考，我这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，
  - 你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西；
  - 然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

