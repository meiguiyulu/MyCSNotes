### 计算机网络

*************

#### 1、网络体系结构

![image-20210405172013732](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210405172013732.png)

**为什么OSI进行七层划分，而非六层等？**

```markdown
**
OSI 七层模型的每一层都具有清晰的特征。
> 第七至第四层处理数据源和数据目的地之间的端到端通信;
> 第三至第一层处理网络设备间的通信。
OSI 模型的七层也可以划分为两组：上层(层7 、层6 和层5)和下层(层4 、层3 、层2 和层1)。 OSI 模型的上层处理应用程序问题，并且通常只应用在软件上。最高层，即应用层，是与终端用户最接近的。 OSI 模型的下层是处理数据传输的。物理层和数据链路层应用在硬件和软件上。最底层，即物理层，是与物理网络媒介(比如说，电线)最接近的，并且负责在媒介上发送数据。
```



##### 应用层

> 应用层(application-layer)的任务是通过应用进程间的交互来完成特定网络应用。
>
> 网络协议：域名系统DNS，HTTP协议、SMTP协议等。
>
> 数据单元：报文。

##### 表示层

> 表示层(Presentation Layer)的基本作用就是对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。
>
> **网络协议：**ASCII、PICT、TIFF、JPEG、 MIDI、MPEG。
>
> 比如说：电脑从收到一串数据时，这些数据在电脑中都是都是二进制的格式，我们人类是看不懂二进制的，就需要表示层帮忙将这些二进制转换成我们能够识别的数据。
>
> OSI表示层例子一
>
> A电脑用浏览器浏览网站B，在网站B里有一张 `gif` 图片，但是B电脑无法识别gif格式的图片，于是在A电脑的浏览器里应该显示这张gif图片的地方会显示为叉叉。
>
> 各位可以先看看“OSI的封装和解封装”，网络设备之间传递数据时会有对数据进行封装的过程，接收数据包是一个解封装的过程，从物理层依次解封装至表示层之后，表示层会检查电脑中是否有能识别该gif图片的解码工具，如果有，则将gif图片展现在相应的应用程序中；如果没有，则提示打不开，或显示出一堆乱码。
>
> OSI表示层例子二
>
> A电脑浏览B网站，B网站是音乐网站，里面有很多mp3音乐，如果A电脑里没有按照能够播放mp3的解码器，那么在A电脑里打开B网站上的mp3文件时，会出现“缺少解码器”等相应的提示。如果A电脑安装了mp3音乐的解码器，就可以打开这个mp3音乐了。
>
> OSI表示层例子三
>
> A电脑浏览B网站，在B网站的服务器中启用了网页压缩 `gzip` 功能，如果A电脑的浏览器无法解压 `gzip` 压缩过的网页，那么就无法正常打开B网站。
>
> 数据单元：表示层的PDU为：PPDU(表示层协议数据单元)。

##### 会话层：

> 会话层(Session Layer)的作用：
>
> - 建立会话：A、B两台网络设备之间要通信，要建立一条会话供他们使用，在建立会话的过程中也会有身份验证，权限鉴定等环节； 
> - 保持会话：通信会话建立后，通信双方开始传递数据，当数据传递完成后，OSI会话层不一定会立刻将两者这条通信会话断开，它会根据应用程序和应用层的设置对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局； 
> - 断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。或者A、B重启、关机、手动执行断开连接的操作时，OSI会话层也会将A、B之间的会话断开。
>
> 
>
> OSI会话层的PDU为：SPDU(OSI会话层协议数据单元)

##### 运输层

> 运输层(transport layer的主要任务是负责向两台主机进程之间的通信提供通用的数据传输服务。

两种协议：

- **传输控制协议TCP(Transmission Control Protocol)----提供面向连接的，可靠的数据传输服务**
- **用户数据协议UDP(User Datagram Protocol)----提高无连接的，尽最大努力的数据传输服务**

##### 网络层

> 网络层的任务是选择合适的网间路由和交换结点，确保数据及时传送。
>
> > 网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。
>
> 在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫作**IP数据报**，或简称**数据报**。
>
> 互联网是由大量的**异构(heterogeneous)网络来通过路由器(Router)**相互连接起来的。**互联网使用的网络层协议是无连接的网际协议IP**(Internet Protocol)和许多**路由选择协议**, 因此互联网的网络层也叫作**网际层**或**IP层**。
>
> 网络设备：
>
> ​	路由器(网关)：连接不同的网络；选择信息传送的线路。

##### 数据链路层

> 数据链路层(data link layer)简称为链路层。两台主机之间的数据传输，总是在一段一段的在链路上传送的，这就需要使用专门的链路层的协议。
>
> 在两个相邻结点之间传送数据时，数据链路层将网络层交下来的**IP数据报封装成帧(frame)**,在两个相邻节点间的链路上传送帧, 每一帧包括数据和必要的**控制信息**(如同步信息、地址信息、差错信息等)。
>
> 数据单元：帧。
>
> **MAC地址：** MAC 地址用于识别数据链路中互连的节点，在使用网卡的情况下，MAC 地址，而且全球唯一。在同一个数据链路里(比如同一个局域网)，互连的主机之间通过 MAC 地址即可实现相互通信。
>
> **网络协议：**ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等。
>
> 网络设备：
>
> - 交换机：物理编址、网络拓扑结构、错误校验、帧序列以及流控。
> - 网卡：有帧的发送与接收、帧的封装与拆封、介质访问控制、数据的编码与解码以及数据缓存的功能

##### 物理层

> 数据单位：比特。
>
> 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。
>
> 功能：根据所使用的传输介质不同，制定不同的物理层协议，规定数据的编码方式，传输速率，相关的通信参数。
>
> 传输介质：同轴电缆、双绞线、光纤。
>
> 协议：点到点通信的物理协议；广播通信的物理协议；
>
> 数据通信方式：
>
> ​		单工通信：只能由主机A向主机B发送数据。信号只能朝一个方向传输。
>
> ​		半双工通信：信号可以两个方向传输，但是必须交替进行，一个时间只能向一个方向传输。
>
> ​		全双工通信：信号可以两个方向传输，双方可以同时向对方发送数据。
>
> 网络设备：
>
> - ​	中继器：它的作用是放大信号，补偿信号衰减，支持远距离的通信。
> - ​	集线器：提供信号放大和中转的功能，有信号广播。中继器与集线器的区别在于连接设备的线缆的数量。一个中继器通常只有两个端口，而一个集线器通常有4至20个或更多的端口

****************

#### 2、多路复用技术

多路复用(multiplexing)，简称复用，是通信技术中的基本概念 。

多路复用技术的原理就是，把通信资源或者说是链路、信道资源进行的划分，分成一系列的资源片。把这些资源片分配给每一路通信。每一路通信在通信过程中就独占它分配到的分配资源。当然在整个通信过程中，可能或出现闲置。

**典型的多路复用技术有：**

- 频分多路复用( frequency division multiplexing-FDM ) 

  - > 将我们的信道资源按频率上进行划分，分成一个个频带的子信道，让每个信号只去用其中的某一个频带的子信道。
    >
    > ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20190212162956828.png)
    >
    > 家里的电视有很多频道，这种电视信号就是这种频分多路复用技术。
    >
    >  用户在分配到一定的频带后，在通 信过程中自始至终都占用这个频带 。
    >
    > ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20190212163210414.png)

- 时分多路复用( time division multiplexing-TDM ) 

  - > 将时间划分为一段段等长的时分复 用帧(TDM 帧)，每个用户在每个 TDM 帧中占 用固定序号的时隙 。
    >
    > 每用户所占用的时隙是周期性出现(其周期就是 TDM  帧的长度) 
    >
    > 时分复用的所有用户是在不同的时间占用相同的 频带宽度 。
    >
    > ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/2019021216353216.png)

- 波分多路复用(Wavelength division multiplexing-WDM) 

  - > ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20190212163606484.png)

- 码分多路复用( Code division multiplexing-CDM ) 

******

#### 3、ARP协议

工作在OSI体系结构的数据链路层。

**ARP(Address Resolution Protocol)即地址解析协议， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址**。



**工作流程**

同一个局域网里面，当PC1需要跟PC2进行通信时，此时PC1是如何处理的？

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/v2-e350c54794f261231f784a973708b9e9_720w.jpg)

根据OSI数据封装顺序，发送方会自顶向下(从应用层到物理层)封装数据，然后发送出去，这里以PC1 ping PC2的过程举例

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/v2-482e369fa6a8c4246af0164fbc69e2fc_720w.jpg)

PC1封装数据并且对外发送数据时，上图中出现了"failed"，即数据封装失败了，为什么？

我们给PC1指令-"ping ip2"，这就告知了目的IP，此时PC1便有了通信需要的源目IP地址，但是PC1仍然没有通信需要的目的MAC地址。**这就好比我们要寄一个快递，如果在快递单上仅仅写了收件人的姓名(IP)，却没有写收件人的地址(MAC)，那么这个快递就没法寄出，因为信息不完整。**

那么，现在PC1已经有了PC2的IP地址信息，如何获取到PC2的MAC地址呢？此时，ARP协议就派上用场了。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/v2-12c0720dbf1143fb4ace0cb44398508f_720w.jpg)

通过第三和第四步骤，我们看到PC1和PC2进行了一次ARP请求和回复过程，通过这个交互工程，PC1便具备了PC2的MAC地址信息。

在真正进行通信之前，PC1还会将PC2的MAC信息放入本地的【ARP缓存表】，表里面放置了IP和MAC地址的映射信息，例如 IP2<->MAC2。接下来，PC1再次进行数据封装，正式进入PING通信．



#### ==4、TCP三次握手和四次挥手==

##### 4.1、TCP首部

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20190818161727869.png)

- `URG`：表示本报文段中发送的数据是否包含紧急数据。后面的紧急指针字段(urgent pointer)只有当URG=1时才有效；
- `ACK`：表示是否前面确认号字段是否有效。只有当 `ACK=1` 时，前面的确认号字段才有效。`TCP` 规定，连接建立后，`ACK` 必须为 `1` , 带`ACK` 标志的 `TCP` 报文段称为确认报文段；
- `PSH`：提示接收端应用程序应该立即从TCP接收缓冲区中读走数据，为接收后续数据腾出空间。如果为1，则表示对方应当立即把数据提交给上层应用，而不是缓存起来，如果应用程序不将接收到的数据读走，就会一直停留在TCP接收缓冲区中；
- `RST`：如果收到一个 `RST=1` 的报文，说明与主机的连接出现了严重错误(如主机崩溃)，必须释放连接，然后再重新建立连接。或者说明上次发送给主机的数据有问题，主机拒绝响应，带 `RST` 标志的 `TCP` 报文段称为复位报文段；
- `SYN`：在建立连接时使用，用来同步序号。当 `SYN=1，ACK=0` 时，表示这是一个**请求建立连接**的报文段；当`SYN=1，ACK=1` 时，表示**对方同意建立连接**。`SYN=1` ，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 `SYN` 才置为 `1`，带 `SYN` 标志的 `TCP` 报文段称为同步报文段；
- `FIN`：表示通知对方本端要关闭连接了，标记数据是否发送完毕。如果 `FIN=1` ，即告诉对方：“我的数据已经发送完毕，你可以释放连接了”，带 `FIN` 标志的 `TCP` 报文段称为**结束报文段**。

##### ==4.2、三次握手==

![三次握手](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA1MTEwNDA1NjY2)

- 客户端发送带有 `SYN=1, seq=x` 标志的数据包，请求连接；
- 服务端发送带有 `SYN=1, ACK=1, seq=y, ack=x+1` 标志的数据包，确认收到消息；
- 客户端发送带有 `ACK=1, seq=x+1 ack=y+1` 标志的数据包，确认收到消息;

###### 1、为什么要三次握手

三次握手的目的是建立可靠的通信信道。说到通信，简单来说就是数据的发送和接收，而三次握手最主要目的就是**双方确认自己与对方的发送与接受是正常的**。

- 第一次握手：client什么都不能确认；Server确认对方发送正常，自己接受正常。
- 第二次握手：client确认：自己发送、接受正常，对方发送、接受正常；Server确认：对方发送正常，自己接受正常。
- 第三次握手：client确认：自己发送、接受正常，对方发送、接受正常；Server确认：自己发送、接受正常，对方发送、接受正常。

###### 2、为什么TCP客户端最后还要发送一次确认呢？

> 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。
>
> 如果使用的是两次握手建立连接，假设有这样一种场景，==客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到==，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。
>
> 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。

###### 3、为什么要回传SYN

> 为了告诉发送端，我接收到的消息确实就是你发送的信号。

###### 4、传了SYN，为什么还要传ACK

传了SYN，说明**发送方到接收方的道路没有问题**，但**接收方到发送方的通道**还需要ACK信号来验证。

###### 5、最后一次连接断了 ，怎么办？

```markdown
# 服务器重传，不是客户端重传。
**
> 第二步发送的时候会设置超时计时器，如果一直没收到第三步回复，第二步就会重发。计时器应该是在服务端，它发送了SYN, ACK报文后，若迟迟接不到对这个报文的回复，那么它就认为刚刚发送的报文丢失了，应该重新发送SYN, ACK报文。
```

###### 6、SYN泛洪攻击

```markdown
**
讲泛洪攻击之前，我们先了解一下DoS攻击和DDoS攻击，这两个攻击大体相同，前者的意思是：拒绝服务攻击；后者的意思是：分布式拒绝服务攻击。不要看这两个攻击前一个比后一个多了一个字母，后一个攻击比前你一个攻击少了"分布式"三个字，其实他们具体的来说还是有所区分的。
DDoS是DoS攻击中的一种方法。下面我们来详细看一下区分：
> DoS(拒绝服务)：不是DOS操作系统，造成DoS的攻击行为被称为DoS攻击，它的目的是使得计算机或者网络无法提供正常服务。最常见的DOS攻击有计算机网络带宽攻击和连通性的攻击。
> DDoS(分布式拒绝服务)；这个攻击借助于客户/服务器技术，将多个计算机联合起来作为一个攻击平台，对一个或者是多个目标发动攻击，从而成倍的提高就裁决服务攻击的威力。
简单地说，DDoS的攻击威力要大于DoS的攻击威力，DDoS主要是发动群体攻击。
```

SYN泛洪攻击，主要利用的就是TCP三次握手机制的缺陷。

​	A(攻击者)发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当这个服务器返回ACK以后，A不再进行确认，那这个连接就处在了一个挂起的状态，也就是半连接的意思，那么服务器收不到再确认的一个消息，还会重复发送ACK给A。这样一来就会更加浪费服务器的资源。A就对服务器发送非法大量的这种TCP连接，由于每一个都没法完成握手的机制，所以它就会消耗服务器的内存最后可能导致服务器死机，就无法正常工作了。更进一步说，如果这些半连接的握手请求是恶意程序发出，并且持续不断，那么就会导致服务端较长时间内丧失服务功能——这样就形成了 `DoS `攻击。这种攻击方式就称为SYN泛洪攻击。

**SYN泛洪攻击的分类**

```markdown
**
1. 直接攻击
	攻击者用他们自己的没有经过伪装的IP地址快速地发送SYN数据包，这就是所谓的直接攻击。这种攻击非常容易实现，因为它并不涉及攻击者操作系统用户层以下的欺骗或修改数据包。
2. 欺骗式攻击
	SYN洪泛攻击的另一种方式是IP地址欺骗。它比直接攻击方式更复杂一点，攻击者还必须能够用有效的IP和TCP报文头去替换和重新生成原始IP报文
3. 分布式攻击
	对于单个运用欺骗式攻击的攻击者真正的限制因素是如果这些伪装数据包能够以某种方式被回溯到其真正的地址，攻击者将被简单地击败。尽管回溯过程需要一些时间和ISP之间的配合，但它并不是不可能的。但是攻击者运用在网络中主机数量上的优势而发动的分布式SYN洪泛攻击将更加难以被阻止。
```



**如何防范SYN泛洪攻击**

```markdown
**
1. 优化主机系统设置
	比如降低SYN timeout时间，使得主机尽快释放半连接的占用或者采用SYN cookie设置，如果短时间内收到了某个IP的重复SYN请求，我们就认为受到了攻击
2.	基于网络的对策
	2.1 过滤：拒绝将一个源IP地址不属于其来源子网的包进行更远的路由。输入源过滤能够有效地阻止用IP伪装的SYN洪泛攻击。然而这种方法在目前是没用的，因为其很难大规模部署。而且输入源过滤同样不能抵御分布式攻击。
	2.2 采用防火墙设置等外部网络进行拦截：有防火墙或者代理的设备在网络中就能够通过两种方法缓冲SYN洪泛攻击，一种是对连接发起人伪装SYN-ACK包，另一种是对服务器伪装ACK包
```



##### ==4.3、四次挥手==

![image-20220225162924028](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20220225162924028.png)

```bash
# 执行命令"netstat -na"查看到的相关TCP状态解释:
LISTEN:       侦听来自远方的TCP端口的连接请求;
SYN-SENT:     在发送连接请求后等待匹配的连接请求;
SYN-RECEIVED: 在收到和发送一个连接请求后等待对方对连接请求的确认;
ESTABLISHED:  代表一个打开的连接;
FIN-WAIT-1:   等待远程TCP连接中断请求, 或先前的连接中断请求的确认;
FIN-WAIT-2:   从远程TCP等待连接中断请求;
CLOSE-WAIT:   等待从本地用户发来的连接中断请求;
CLOSING:      等待远程TCP对连接中断的确认;
LAST-ACK:     等待原来的发向远程TCP的连接中断请求的确认;
TIME-WAIT:    等待足够的时间以确保远程TCP接收到连接中断请求的确认;
CLOSE:        没有任何连接状态;
```

`ESTABLISHED`：正在通信

`TIME_WAIT `主动关闭连接时形成的，等待 `2MSL` 时间，约4分钟。主要是防止最后一个ACK丢失。  由于TIME_WAIT 的时间会非常长，因此server端应尽量减少主动关闭连接。

`CLOSE_WAIT `：被动关闭连接时形成的。根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时，recv/read已收到FIN的连接socket，会返回0。



- 客户端-发送一个 `FIN`，用来关闭客户端到服务器的数据传送(A发送断开请求)
- 服务器-收到这个 `FIN`，它发回一个 `ACK` ，确认序号为收到的序号加 `1`。和 `SYN` 一样，一个 `FIN` 将占用一个序号(B收到请求并回复A)
- 服务器-关闭与客户端的连接，发送一个 `FIN` 给客户端(B这边准备完了，通知A可以断开了)
- 客户端-发回 `ACK` 报文确认，并将确认序号设置为收到序号加1(A回复B，我收到消息了，断开连接吧)

###### **为什么要四次挥手, 不是三次？**

这是因为服务端在 `LISTEN` 状态下，收到客户端发送的断开连接的FIN报文后，可能会有数据未发送完成，需要继续发送，因此不能将确认消息和请求关闭消息同时发送，而是会先关闭接收服务回复确认消息，然后继续发送未完消息到客户端，直到发送结束，再发送请求关闭消息。

举个例子：A和B打电话，通话即将结束后，A说“我没啥要说的了”，B回答“我知道了”，但是B可能还会有要说的话，A不能要求B跟着自己的节奏结束通话，于是B可能又巴拉巴拉说了一通，最后B说“我说完了”，A回答“知道了”，这样通话才算结束。

###### 为什么客户端要等待2MSL(Time_WAIT)

> `MSL(Maximum Segment Lifetime)报文的最大生存时间(发送和回复所需的最大时间)`，TCP允许不同的实现可以设置不同的`MSL `值。
>
> ```markdown
> # 第一 保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了 `FIN+ACK` 报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个 `2MSL` 时间段内收到这个重传的报文，接着给出回应报文，并且会重启 `2MSL` 计时器。若A在 `TIME-WAIT` 状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到B重传的连接释放报文段，所以不会再发送一次确认报文段，B就无法正常进入到CLOSED状态。
> 
> # 第二 防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个 `2MSL` 时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。
> ```



###### **TCP 连接关闭的详细过程**

TCP协议的连接是全双工连接，一个TCP连接存在**双向的读写**通道。 

简单说来是 “先关读，后关写”，一共需要四个阶段。以客户机发起关闭连接为例 ：

1. 服务器读通道关闭
2. 客户机写通道关闭
3. 客户机读通道关闭
4. 服务器写通道关闭

关闭行为是在连接的发起方数据发送完毕之后，给对方发出一个FIN(finish)数据段。直到 接收到对方发送的FIN，且对方收到了接收确认ACK之后 ，双方的数据通信完全结束，过程中每次接收都需要 返回确认数据段ACK。



###### **服务器先关闭，客户端不关闭，继续发送数据，会出现什么情况？**

服务器：发出 `FIN`, 客户端回复 `ACK`，进入 `TIME_WAIT `状态

客户端：没有 `close()`, 处于 `close_wait()` 状态，接着向服务器继续发送数据，会出现什么情况？

客户端：因为对方关闭(相当于管道中对方的读端关闭写端写满缓冲区就会触发SIGPIPE信号，操作系统会强制关闭写端)，客户端继续写的话，会触发 `SIGPIPE `信号，操作系统会强制关闭客户端。



###### **如果已经建立了连接，但是客户端突然出现故障了怎么办？**

> TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。



###### **服务器保持了大量TIME_WAIT状态**

**可能的原因：**

- 存在大量的短连接
- 爬虫服务器

**可能产生的后果：**

- 在socket的 `TIME_WAIT` 状态结束之前，该socket所占用的本地端口号将一直无法释放。如果 `time_wait` 状态把系统所有可用端口都占完了且尚未被系统回收时，就会出现无法向服务端创建新的 socket 连接的情况。此时系统几乎停转，任何链接都不能建立。
- 大量的 `time_wait `状态也会占用系统一定的 `fd(软磁盘)`，内存和 cpu 资源。

**解决方法：**

让服务器能够**快速回收和重用**那些 `TIME_WAIT` 的资源。

下面来看一下对 `/etc/sysctl.conf` 文件的修改：

```bash
# 表示当keepalive启用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为300秒
net.ipv4.tcp_keepalive_time=1200
# 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数
net.ipv4.tcp_max_syn_backlog = 4096
# 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭
net.ipv4.tcp_syncookies = 1
# 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭
net.ipv4.tcp_tw_reuse = 1
# 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭
net.ipv4.tcp_tw_recycle = 1
# 减少超时前的探测次数
net.ipv4.tcp_keepalive_probes=5
```

修改完之后执行`/sbin/sysctl -p`让参数生效。

###### **服务器保持了大量CLOSE_WAIT状态**

​		从上面的图可以看出来，如果一直保持在 `CLOSE_WAIT` 状态，那么只有一种情况，就是**在对方关闭连接之后服务器程序自己没有进一步发出ACK信号**。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是**这个资源就一直被程序占着**。个人觉得这种情况，通过服务器内核参数也没办法解决，服务器对于程序抢占的资源没有主动回收的权利，除非终止程序运行。

********

#### ==5、TCP、UDP==

##### TCP、UDP区别

![image-20210405195521513](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210405195521513.png)

- UDP传送数据之前不需要先建立连接，远地主机在收到UDP报文后，不需要给出任何确认(**不可靠**交付)。用于：QQ语音、QQ视频、直播等。
- TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束要释放连接。不提供广播或者多播服务。
  - TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。
  - TCP一般用于文件传输、发送和接收邮件、远程登录等场景。

##### TCP比UDP到底慢多少

**少了三次握手四次挥手的连接，首部长度也小12字节**

UDP相对于TCP而言，是缺少一个可靠的丢失重发机制，因此可以立即返回，所以觉得快；

UDP属于发射后不管，但是从IP层来说，它的效率和TCP相比，几乎相同。

TCP为什么慢呢？就是因为需要 发射 确认 这样一个循环过程，所以慢。



##### 为什么QQ用的是UDP协议而不是TCP协议？

- QQ既有UDP也有TCP！
- 不管UDP还是TCP，最终登陆成功之后，QQ都会有一个TCP连接来保持在线状态。这个TCP连接的远程端口一般是80，采用UDP方式登陆的时候，端口是8000。
- UDP协议是无连接方式的协议，它的效率高，速度快，占资源少，但是其传输机制为不可靠传送，必须依靠辅助的算法来完成传输控制。QQ采用的通信协议以UDP为主，辅以TCP协议。由于QQ的服务器设计容量是海量级的应用，一台服务器要同时容纳十几万的并发连接，因此服务器端只有采用UDP协议与客户端进行通讯才能保证这种超大规模的服务。
- QQ客户端之间的消息传送也采用了UDP模式，因为国内的网络环境非常复杂，而且很多用户采用的方式是通过代理服务器共享一条线路上网的方式，在这些复杂的情况下，客户端之间能彼此建立起来TCP连接的概率较小，严重影响传送信息的效率。而UDP包能够穿透大部分的代理服务器，因此QQ选择了UDP作为客户之间的主要通信协议。
- 采用UDP协议，通过服务器中转方式。因此，现在的IP侦探在你仅仅跟对方发送聊天消息的时候是无法获取到IP的。大家都知道，UDP 协议是不可靠协议，它只管发送，不管对方是否收到的，但它的传输很高效。但是，作为聊天软件，怎么可以采用这样的不可靠方式来传输消息呢？于是，腾讯采用了上层协议来保证可靠传输：如果客户端使用UDP协议发出消息后，服务器收到该包，需要使用UDP协议发回一个应答包。如此来保证消息可以无遗漏传输。之所以会发生在客户端明明看到“消息发送失败”但对方又收到了这个消息的情况，就是因为客户端发出的消息服务器已经收到并转发成功，但客户端由于网络原因没有收到服务器的应答包引起的。

##### ==TCP协议如何保证可靠传输==

TCP 通过**检验和、序列号、超时重传、以及流量控制、拥塞控制**等机制实现可靠传输。

- **三次握手、四次挥手**
  - TCP 在发送数据之前需要进行 **三次握手** 进行连接。
- **通过序列号与确认应答提高可靠性**
  - TCP 发送数据是将数据分割成数据块发送的。每个数据块都有一个序列号。
  - TCP 将保持它首部和数据的**检验和**。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。
  - TCP中，发送端的数据到达接收主机时，接收端会返回一个已收到的通知。即 **确认应答(ACK)**。在一定时间内没有收到 **确认应答**，发送端就认为数据已经丢失，需要进行重新发送。
  - TCP的接收端会丢弃重复的数据。
- **流量控制**
  - TCP使用**滑动窗口**实现流量控制。
  - TCP连接的每一方都有固定大小的缓冲空间，`TCP` 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。
  - 在使用滑动窗口下的重传：
    - 如果接收端的 **确认应答(ACK)** 没有传到发送端，在这种情况下，可以通过下一个**确认应答(ACK)** 来进行确认。
    - 如果发送端发送的某一个报文段丢失了，比如说发送端一直收到序号为1001的确认应答。**发送端主机如果连续3次收到同一个确认应答，就会将其所对应的数据进行重发。**
- [**拥塞控制**](####9、TCP的拥塞控制)
  - 为了**防止过多的数据注入到网络**中，这样就可以使网络中的路由器或链路不致过载。
  - 有四种算法：满开始、拥塞避免、快重传与快恢复。

------

#### 6、广播和组播

-  网络信息传输主要有4种方式：单播(unicast)、任播(anycast)、组播(multicast)和广播(broadcast)。
- 广播和组播为应用程序提供了两种服务：数据分组交付至多个目的地，通过客户端请求/发现服务器。
  - 交付至多个目的地。有许多应用程序将信息交付至多个收件方，例如，互动式会议、邮件或新闻分发至多个收件方。没有广播或组播，这些类型的服务只能将一个单独的副本交付至每一个目的地，这是非常低效的。
  - 通过客户端请求/发现服务器。使用广播或组播，应用程序可以向一个服务器发送一个请求，而不用知道任何特定服务器的IP地址。当本地网络环境的信息了解得很少时，这种功能在网络配置过程中非常有用。例如嵌入式系统通过DHCP获取其初始IP地址、ARP、IPv6 ND等。
- 组播相对于广播来说更为高效。因为组播只涉及那些支持或使用特定服务或协议的系统，而广播不是。因此，一个广播请求会影响在广播域内所有可以到达的主机，而组播只影响那些可能对该请求“有兴趣”的主机。在广播的更高开销和简单性以及组播的效率改善和更复杂性之间存在一种平衡。

###### 广播

​		广播是指将报文发送到网络中的所有可能的接收者。从原理上这很容易实现：路由器简单地将它接收到的任何广播报文副本转发到除该报文到达的接口以外的每个接口。当多台主机连接到同一个局域网时，广播还能结合链路层特点提供相对更高效的转发策略。

**广播地址**

​		在IPv4中，每个子网都有一个本地定向子网广播地址，它是通过将地址中的主机部分全部置1形成的，特殊的`255.255.255.255` 对应于本地网络广播(也叫有限广播)。

###### 组播

 		为了减少在广播中涉及的不必要的开销，可以只向特定的一部分接收方(可以是域内也可以是域间)发送流量，这被称为组播。从根本上说，通过发送方指明接收方，或是通过接收方独立地指明它们的接收方，就可以完成这项工作。然后网络只负责向预期的或感兴趣的收件方发送流量。

​		实现组播比广播要复杂，因为组播状态(multicast state)(信息)必须由主机和路由器来保持，以说明哪些接收方对哪类流量感兴趣。这个信息作为主机和路由器中的软状态来维持，这意味着它必须定期更新(当这种情况发生时，组播流量的交付要目停止要目恢复为广播)。如果正确地使用组播，只有那些在通信中参与或感兴趣的主机需要处理相关的分组，流量只会被承载于它将被使用的链路上，并且只有任意组播数据报的一个副本被承载于这样的链路上。

​		为了使组播工作，希望参与通信的应用程序需要一种机制来发布其意愿的协议实现。然后主机软件可以安排接收与应用程序的条件相匹配的分组。

###### TCP不能广播和组播

因为 `TCP` 是面向连接的，需要有服务器和客户端的 `ip` 和端口才能进行通讯。

###### UDP 如何实现广播？

广播UDP与单播UDP的区别就是IP地址不同，广播使用广播地址 `255.255.255.255`，将消息发送到在同一广播网络上的每个主机。值得强调的是：**本地广播信息是不会被路由器转发**。当然这是十分容易理解的，因为如果路由器转发了广播信息，那么势必会引起网络瘫痪。这也是为什么IP协议的设计者故意没有定义互联网范围的广播机制。

广播地址通常用于在网络游戏中处于同一本地网络的玩家之间交流状态信息等。

其实广播顾名思义，就是想局域网内所有的人说话，**但是广播还是要指明接收者的端口号的**，因为不可能接受者的所有端口都来收听广播。

**广播与单播的比较：**

广播和单播的处理过程是不同的，单播的数据只是收发数据的特定主机进行处理，而广播的数据整个局域网都进行处理。

例如在一个以太网上有3个主机，主机的配置如表11.4所示。

![image-20210805192914297](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210805192914297.png)

　单播流程：主机A向主机B发送UDP数据报，发送的目的IP为192.168.1.151，端口为 80，目的MAC地址为00:00:00:00:00:02。此数据经过UDP层、IP层，到达数据链路层，数据在整个以太网上传播，在此层中其他主机会 判断目的MAC地址。主机C的MAC地址为00:00:00:00:00:03，与目的MAC地址00:00:00:00:00:02不匹配，数据链路层 不会进行处理，直接丢弃此数据。主机B的MAC地址为00:00:00:00:00:02，与目的MAC地址00:00:00:00:00:02一致，此数据会经过IP层、UDP层，到达接收数据的应用程序。

广播的流程：主机A向整个网络发送广播数据，发送的目的IP为192.168.1.255，端口为 80，目的MAC地址为FF:FF:FF:FF:FF:FF。此数据经过UDP层、IP层，到达数据链路层，数据在整个以太网上传播，在此层中其他主机会 判断目的MAC地址。由于目的MAC地址为FF:FF:FF:FF:FF:FF，主机C和主机B会忽略MAC地址的比较(当然，如果协议栈不支持广播，则 仍然比较MAC地址)，处理接收到的数据。

主机B和主机C的处理过程一致，此数据会经过IP层、UDP层，到达接收数据的应用程序。

------

#### 7、ARQ协议

`ARQ协议`

> 自动重传请求(Automatic Repeat-request, ARQ)是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过**确实**和**超时**两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送发在一段时间之内没有收到确认帧，它就会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。

###### 停止等待ARQ

- 停止等待协议是为了**实现可靠传输**的，它的基本原理就是每发完一个分组就停止发送，等待对方确认(回复ACK)。如果过了一段时间(超时时间后)，还是没有收到ACK确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

优点：简单
缺点：信道利用率低，等待时间长
1)无差错情况：
发送方发送分组，接收方在规定时间内收到，并且回复确认.发送方再次发送。<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/3256507-8c5662098685040e.webp.jpg" alt="3256507-8c5662098685040e.webp" style="zoom:33%;" />

2)出现差错情况(超时重传)：
停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组(认为刚才发送过的分组丢失了)。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARO。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续ARO协议可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/3256507-528054e4a0cad4c0.webp.jpg" alt="3256507-528054e4a0cad4c0.webp" style="zoom:33%;" />

3)确认丢失和确认迟到

- 确认丢失：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1.丢弃这个重复的M1消息，不向上层交付。2.向A发送确认消息。(不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失)。<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/3256507-6c6f83c2e096afd6.webp.jpg" alt="3256507-6c6f83c2e096afd6.webp" style="zoom:33%;" />
- 确认迟到：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息(B收到了2份M1)。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息(A也收到了2份确认消息)。处理如下：1.A收到重复的确认后，直接丢弃。2.B收到重复的M1后，也直接丢弃重复的M1。<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/3256507-74c114877f8b0f0d.webp.jpg" alt="3256507-74c114877f8b0f0d.webp" style="zoom:33%;" />

###### 连续ARQ协议

连续ARQ协议可**提高信道利用率**。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

优点：信道利用率高，容易实现，即使确认丢失，也不必重传。

缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。比如：发送方发送了5条消息，中间第三条丢失(3号)，这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫Go-Back-N(回退N)，表示需要退回来重传已经发送过的N个消息。

#### 8、滑动窗口和流量控制

TCP利用**滑动窗口实现流量控制**。流量控制是为了**控制发送方发送速率**，保证接收方来得及接受。

> - TCP使用**滑动窗口**实现流量控制。
> - TCP连接的每一方都有固定大小的缓冲空间，`TCP` 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。
> - 在使用滑动窗口下的重传：
>   - 如果接收端的 **确认应答(ACK)** 没有传到发送端，在这种情况下，可以通过下一个**确认应答(ACK)** 来进行确认。
>   - **发送端主机如果连续3次收到同一个确认应答，就会将其所对应的数据进行重发。**

#### ==9、TCP的拥塞控制==

> 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。

> 拥塞控制就是为了**防止过多的数据注入到网络**中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。
>
> - 拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。
> - 流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

为了进行拥塞控制，TCP发送方要维持一个 **拥塞窗口(`cwnd`)**的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗囗和接收方的接受窗口中较小的一个。

TCP的拥塞控制采用了四种算法，即**慢开始、拥塞避免、快重传和快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略(如主动队列管理AQM)，以减少网络拥塞的发生。

###### **慢开始** 

​		慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。`cwnd` 初始值为1，每经过一个传播轮次，`cwnd` 加倍。

###### **拥塞避免**

拥塞避免算法的思路是当 **拥塞窗口`cwnd`** 超过阈值 `ssthresh` 以后让拥塞窗口 `cwnd` 缓慢增大，即每经过一个往返时间`RTT`就把发送方的 `cwnd` 加1。

当发生网络拥塞的时候，新的**`ssthresh`**阈值大小变为当前 **拥塞窗口`cwnd`**的一半。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20180410215943968)

###### **快重传与快恢复**

 **快重传**算法：首先要求接收方每收到一个失序的报文段就立即发出重复确认(为的是使发送方及早知道有报文段没有到达对方)，然后若是**发送方接收到3个重复确认ACK，则启动快重传算法**。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20180410220004265)

**快恢复**算法

![image-20210405202447884](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210405202447884.png)

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20190731184935595.png)

********

#### 10、IP协议详解

网络层的协议。

**分类寻址**

IPV4被分为五大类：ABCDE

A类为：点分四组中的第一组地址范围为0~127的IP地址。已二进制来看就是“首位为0”

B类：第一组地址范围是128~191.二进制首位为10

C类：第一组地址范围是192~223.二进制首位为110

D类：第一组地址范围是224~239.二进制首位为1110

E类：第一组地址范围是240~255.二进制首位为1111



![image-20210805202031758](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210805202031758.png)

**IP协议是不可靠的协议，因为IP协议是无连接的。**

***************

#### ==11、输入url到显示页面的全过程==

> 域名解析 –>与服务器建立连接(发起TCP的3次握手) –> 建立TCP连接后发起http请求 –> 服务器响应http请求，浏览器得到html代码 –> 浏览器解析html代码，并请求html代码中的资源(如js、css、图片等) –> 浏览器对页面进行渲染呈现给用户。
>
> 使用到的协议：
>
> - DNS：获取域名对应的IP地址，完成网址到IP地址的转换。
> - TCP：与服务器建立TCP连接
> - IP：建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议
> - OPSF：IP数据包在路由器之间，路由器使用OPSF协议
> - ARP：将ip地址转换为MAC地址
> - HTTP：TCP建立完成后，使用HTTP协议访问网页。

1. DNS解析

   DNS解析的过程就是寻找哪台机器上有你需要资源的过程。当你在浏览器中输入一个地址时，例如www.baidu.com，其实不是百度网站真正意义上的地址。互联网上每一台计算机的唯一标识是它的IP地址，但是IP地址并不方便记忆。用户更喜欢用方便记忆的网址去寻找互联网上的其它计算机，也就是上面提到的百度的网址。所以互联网设计者需要在用户的方便性与可用性方面做一个权衡，这个权衡就是**一个网址到IP地址的转换，这个过程就是DNS解析**。它实际上充当了一个翻译的角色，实现了网址到IP地址的转换。

   - **查看浏览器内部缓存**     检测域名是否存在于浏览器缓存中，如果有缓存直接使用，没有则下一步。打开 `chrome://net-internals/#dns` 即可查看本机浏览器的 `dns` 缓存。
   - **查看系统缓存**   浏览器会调用一个类似 `gethostbyname` 的库函数，此函数会先去检测本地 hosts 文件，查看是否有对应 ip。
   - **查看路由器缓存、ISP 缓存**   如果浏览器和系统缓存都没有，系统的 gethostname 函数就会像 DNS 服务器发送请求。而网络服务一般都会先经过路由器以及网络服务商(电信)，所以会先查询路由器缓存，然后再查询 ISP 的 DNS 缓存。
   - **查看本地 DNS 服务器**   通常为自己计算机搭建的小型 DNS 服务器，自我使用，属于 DNS 优化的一部分。
   - **查看域名服务器**    到此处的过程为：`根域服务器(.)` -> `顶级域名服务器(eg: .com，.org)`->`主域名服务器(eg: google.com)`。如果域名正常，应该就会返回 IP 地址，如果没有浏览器就会提示找不到服务器地址。

   ![preview](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/bVDM45)

2. TCP连接(三次握手)

3. 发送HTTP请求

   发送HTTP请求的过程就是构建HTTP请求报文并通过TCP协议中发送到服务器指定端口(HTTP协议80/8080, HTTPS协议443)。HTTP请求报文是由三部分组成: **请求行**, **请求报头**和 **请求正文**。

   ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20200923143437600.jpg)

4. 服务器处理请求并返回HTTP报文

5. 浏览器解析渲染页面

   ```markdown
   1. 解析HTML的结构
   	把标签转换成内容树中的DOM节点
   2. 浏览器如何解析css
   	2.1 CSS选择器的读取顺序是从右向左。
   	2.2　比如：#molly div.haha span{color:#f00}　浏览器会按照从右向左的顺序去读取选择器。先找到span然后顺着往上找到class为“haha”的div再找到id为“molly”的元素。
   3. 浏览器如何解析js
   	3.1 js预解析
   	3.2 逐行解析代码
   ```

6. 连接结束(长连接、短连接)



##### DNS实现一个域名对应对个IP地址

**负载均衡 + 一致性哈希**

​		在DNS系统中有一个比较重要的的资源类型叫做主机记录也称为A记录，A记录是用于名称解析的重要记录，它将特定的主机名映射到对应主机的IP地址上。如果你有一个自己的域名，那么要想别人能访问到你的网站，你需要到特定的DNS解析服务商的服务器上填写A记录，过一段时间后，别人就能通过你的域名访问你的网站了。DNS除了能解析域名之外还具有负载均衡的功能，下面是利用DNS工作原理处理负载均衡的工作原理图：

![image-20210815213354717](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210815213354717.png)



[一致性哈希](https://www.zsythink.net/archives/1182)



##### Web优化

上面部分主要介绍了一次完整的请求对应的过程，了解该过程的目的无非就是为了Web优化。在谈到Web优化之前，我们回到一个更原始的问题，Web前端的本质是什么。我的理解是: **将信息快速并友好的展示给用户并能够与用户进行交互**。快速的意思就是在尽可能短的时间内完成页面的加载，试想一下当你在淘宝购买东西的时候，淘宝页面加载了10几秒才显示出物品，这个时候你还有心情去购买吗？怎么快速的完成页面的加载呢？优雅的学院派雅虎给出了常用的一些手段，也就是我们熟悉的[雅虎34条军规](https://developer.yahoo.com/performance/)。这34军规实际上就是围绕请求过程进行的一些优化方式。

**减少查询过程，也就是 DNS 缓存。浏览器获取到 IP 地址后，一般都会加到浏览器的缓存中，本地的 DNS 缓存服务器，也可以去记录。另外，每天几亿网名的访问需求，一秒钟几千万的请求域名服务器如何满足？就是 DNS 负载均衡。**

如何尽快的加载资源？答案就是能不从网络中加载的资源就不从网络中加载，当我们**合理使用缓存，将资源放在浏览器端**，这是最快的方式。如果资源必须从网络中加载，则要考虑缩短连接时间，即DNS优化部分;减少响应内容大小，即对内容进行压缩。另一方面，如果加载的资源数比较少的话，也可以快速的响应用户。当资源到达浏览器之后，浏览器开始进行解析渲染，浏览器中最耗时的部分就是reflow，所以围绕这一部分就是考虑如何减少reflow的次数。

##### 为什么URL要解析(也就是编码)

URL中有些字符会引起歧义：因为网络标准规定了URL只能是字母和数字，还有一些其它特殊符号`(-_.~ ! * ' ( ) ; : @ & = + $ , / ? # [ ]`，比较常见的就是不包括百分号和双引号)，而且如果不转义会出现歧义，比如 `http:www.baidu.com?key=value`,如果你的value字符串中包含了=或者&，那么势必会造成接收URL的服务器解析错误，因此必须将引起歧义的&和=符号进行转义，也就是对其进行编码。

> URL的编码格式采用的是ASCII码，而不是Unicode，这也就是说你不能在URL中包含任何非ASCII字符，例如中文。否则如果客户端浏览器和服务端浏览器支持的字符集不同的情况下，中文可能会造成问题。

##### HTTP连接复用

浏览器输入 `url` 的解析过程中耗时的部分：

1. DNS的查询时间
2. TCP建立连接的需要三次握手
3. 发起 HTTP 请求需要构建 `request`
4. 服务器发送 `response` 到客户端的时间
5. 四次握手关闭连接所需要的时间
6. 客户端接收数据渲染页面的时间

**复用：**

- `HTTP/1.0` 默认使用短连接，`HTTP/1.1` 中改为了默认使用 **长连接**。这样可以省去 三次握手、四次挥手等时间。
- **多路复用**代替了原来的**序列和阻塞机制**，所有的请求都是通过一个TCP连接并发完成的。
  - 在 `HTTP/2` 中，有了二进制分帧之后，HTTP/2 不再依赖 TCP 链接去实现多流并行了，在 HTTP/2 中：
    - **同域名下所有通信都在单个连接上完成，同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应**。
    - **单个连接可以承载任意数量的双向数据流，单个连接上可以并行交错的请求和响应，之间互不干扰**。
    - **数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。每个请求都可以带一个 31bit 的优先值，0 表示最高优先级， 数值越大优先级越低**



#### 12、状态码

![image-20210405203222946](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210405203222946.png)

>**2xx (3种)**
>
>> - **200** 请求成功
>> - **204 No Content**：表示客户端发送给客户端的请求得到了成功处理，但在返回的响应报文中不含实体的主体部分(没有资源可以返回)；
>> - **206 Partial Content：**表示客户端进行了范围请求，并且服务器成功执行
>> - 了这部分的GET请求，响应报文中包含由Content-Range指定范围的实体内容
>
>**3xx (5种)**
>
>>- **301 Moved Permanently：**永久性重定向，表示请求的资源被分配了新的URL，之后应使用更改的URL；
>
>>- **302 Temporary Redirect：**临时性重定向，表示请求的资源被分配了新的URL，希望本次访问使用新的URL；
>
>>  > 301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取(用户看到的效果就是他输入的地址A瞬间变成了另一个地址B)——这是它们的共同点。他们的不同在于。301表示旧地址A的资源已经被永久地移除了(这个资源不可访问了)，**搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址**；302表示旧地址A的资源还在(仍然可以访问)，这个重定向只是临时地从旧地址A跳转到地址B，**搜索引擎会抓取新的内容而保存旧的网址。**
>
>>- **303 See Other**：表示请求的资源被分配了新的URL，应使用GET方法定向获取请求的资源；
>
>>- **304 Not Modified：**表示客户端发送附带条件(是指采用GET方法的请求报文中包含if-Match、If-Modified-Since、If-None-Match、If-Range、If-Unmodified-Since中任一首部)的请求时，服务器端允许访问资源，但是请求为满足条件的情况下返回改状态码；
>
>>- **307 Temporary Redirect**：临时重定向，与303有着相同的含义，307会遵照浏览器标准不会从POST变成GET；(不同浏览器可能会出现不同的情况)；
>
>**4xx (4种)**
>
>>- **400 Bad Request：**表示请求报文中存在语法错误；
>>- **401 Unauthorized：**未经许可，需要通过HTTP认证；
>>- **403 Forbidden**：服务器拒绝该次访问(访问权限出现问题)
>>- **404 Not Found：**表示服务器上无法找到请求的资源，除此之外，也可以在服务器拒绝请求但不想给拒绝原因时使用；
>
>**5xx (2种)**
>
>> - **500 Inter Server Error：**表示服务器在执行请求时发生了错误，也有可能是web应用存在的bug或某些临时的错误时；
>> - **503 Server Unavailable：**表示服务器暂时处于超负载或正在进行停机维护，无法处理请求。

#### ==13、HTTP==

##### 介绍一下HTTP

> HTTP是超文本传输协议，是用于从万维网服务器传输超文本到本地浏览器的传送协议。在OSI七层模型中处于最顶层的应用层的协议。
>
> 是基于TCP协议。

###### [HTTP头部](https://blog.csdn.net/sinat_34166518/article/details/83584910)

https://www.jianshu.com/p/a797e6eff804

###### ==HTTP的报文结构==

**Request：请求报文**包括三部分:

- `Request line`：请求行
  - 请求方法：`OPTIONS`、`HEAD`、`GET`、`POST`、`PUT`、`DELETE`、`CONNECT`
- `Request header`：请求头部
- 空行
- 请求数据

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/2012072810301161.png)

**常见的HTTP请求报文头属性**

```markdown
# 1. Accept
	1.1 请求报文可通过一个“Accept”报文头属性告诉服务端 客户端接受什么类型的响应。比如：Accept:text/plain  代表只接受纯文本。	
# 2. Cookie
	2.1 客户端的Cookie就是通过这个报文头属性传给服务端.Cookie: $Version=1; Skin=new;jsessionid=5F4771183629C9834F8382E23BE13C4C  
# 3. Referer  
	表示这个请求是从哪个URL过来的，假如你通过google搜索出一个商家的广告页面，你对这个广告页面感兴趣，鼠标一点发送一个请求报文到商家的网站，这个请求报文的Referer报文头属性值就是http://www.google.com
# 4. Cache-Control
	对缓存进行控制，如一个请求希望响应返回的内容在客户端要被缓存一年，或不希望被缓存就可以通过这个报文头达到目的。
	Cache-Control: no-cache表示服务端将对应的相应内容不放在客户端缓存。
# 5. User-Agent: 浏览器表明自己的身份(是哪种浏览器)。
	例如：User-Agent：Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN;
rv:1.8.1.14) Gecko/20080404 Firefox/2.0.0.14。
# ...
```



**Response： 响应报文**包含三部分:

- 相应行：包含HTTP版本, 状态码 ,状态码原因等；
- 响应头；
- 响应体。

比如说一个实际的HTTP响应报文：

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/bddb00b6-a3e1-3112-a4f4-4b3cb8687c70.jpg)

**常见的HTTP响应报文头属性**

```markdown
# 1. Cache-Control  
	响应输出到客户端后，服务端通过该报文头属告诉客户端如何控制响应内容的缓存。 
# 2. ETag  
	一个代表响应服务端资源(如页面)版本的报文头属性，如果某个服务端资源发生变化了，这个ETag就会相应发生变化。它是Cache-Control的有益补充，可以让客户端“更智能”地处理什么时候要从服务端取资源，什么时候可以直接从缓存中返回响应。 
# 3. Location
	我们在JSP中让页面Redirect到一个某个A页面中，其实是让客户端再发一个请求到A页面，这个需要Redirect到的A页面的URL，其实就是通过响应报文头的Location属性告知客户端的，如下的报文头属性，将使客户端redirect到iteye的首页中：Location: http://www.iteye.com  
# 4. Set-Cookie
	服务端可以设置客户端的Cookie，其原理就是通过这个响应报文头属性实现的： Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1  
# ...
```



##### ==GET请求与POST请求的区别==

- `GET` 将数据放在 `URL` 中，`POST` 将数据放在 `BODY` 中；
- `GET`产生一个`TCP`数据包；`POST`产生两个`TCP`数据包。对于`GET`方式的请求，浏览器会把请求头和请求体一并发送出去；而对于`POST`，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体。
- `GET`请求只能进行 `url` 编码，而`POST`支持多种编码方式。
- `GET`，特定的浏览器和服务器对 `URL` 的长度有限制。因此，在使用GET请求时，传输数据会受到URL长度的限制。对于POST，由于不是URL传值，理论上是不会受限制的，但是实际上**各个服务器会规定对POST提交数据大小进行限制**。比如说：*关于 `maxPostSize`,　tomcat 默认是 `2M`，单位为字节。*修改Tomcat服务器 `conf` 文件夹下 `server.xml` 文件中的**`maxPostSize = -1`**，不限制post请求大小进行限制。
- `POST` 的安全性比 `GET` 的高，因为 `GET` 请求的数据在地址栏上可见。

##### ==HTTP长连接、短连接==

在 `HTTP/1.0` 中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源(如JavaScript文件、图像文件、CSS文件等)，每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从 `HTTP/1.1` 起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：`Connection:keep-alive`

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。`Keep-Alive` 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件(如Apache)中设定这个时间。*实现长连接需要客户端和服务端都支持长连接。*

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。**

##### **TCP长/短连接的应用场景**

1、长连接多用于操作频繁，点对点的通讯，而且连接数不能太多的情况。每个TCP连接都需要三次握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，再次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

2、而像WEB网站的http服务一般都用短连接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接好。

##### HTTP是不保存状态的协议，如何保存用户状态？

​		HTTP 是一种不保存状态，即无状态(stateless)协议。也就是说HTTP协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，**Session的主要作用就是通过服务端记录用户的状态**。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，**因为HTTP协议是无状态的。服务端给特定的用户创建特定的Session 之后就可以标识这个用户并且跟踪这个用户了(一般情况下，服务器会在一定时间内保存这个Session，过了时间限制，就会销毁这个Session)。**
​		在服务端保存 Session的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现Session跟踪呢？大部分情况下，我们都是通过在**Cookie 中附加一个Session ID**来方式来跟踪。
Cookie 被禁用怎么办？
最常用的就是利用URL重写把Session ID直接附加在URL路径的后面。

##### ==Cookie、Session、Token==

###### Cookie

```markdown
**
1. Cookie的定义?
	指某些网站为了辨别用户身份、进行session跟踪而存储在用户本地终端上的数据(通常经过加密)。也就是说如果知道一个用户的Cookie，并且在Cookie有效的时间内，就可以利用Cookie以这个用户的身份登录这个网站。
**
**
2. 会话cookie和持久cookie的区别？
	如果不设置过期时间，则表示这个cookie生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。这种生命期为浏览会话期的cookie被称为会话cookie。会话cookie一般不保存在硬盘上而是保存在内存里。
	如果设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie依然有效直到超过设定的过期时间。
	存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存的cookie，不同的浏览器有不同的处理方式。
**
```

###### Cookie的一些特性

- **Cookie的不可跨域名性**

  - 很多网站都会使用Cookie。例如，Google会向客户端颁发Cookie，Baidu也会向客户端颁发Cookie。那浏览器访问Google会不会也携带上Baidu颁发的Cookie呢？或者Google能不能修改Baidu颁发的Cookie呢？

    答案是否定的。**Cookie具有不可跨域名性**。根据Cookie规范，浏览器访问Google只会携带Google的Cookie，而不会携带Baidu的Cookie。Google也只能操作Google的Cookie，而不能操作Baidu的Cookie。

    Cookie在客户端是由浏览器来管理的。浏览器能够保证Google只会操作Google的Cookie而不会操作Baidu的Cookie，从而保证用户的隐私安全。浏览器判断一个网站是否能操作另一个网站Cookie的依据是域名。Google与Baidu的域名不一样，因此Google不能操作Baidu的Cookie。

    需要注意的是，虽然网站`images.google.com`与网站`www.google.com`同属于Google，但是域名不一样，二者同样不能互相操作彼此的Cookie。

    注意：用户登录网站`www.google.com`之后会发现访问 `images.google.com` 时登录信息仍然有效，而普通的 `Cookie` 是做不到的。这是因为Google做了特殊处理。本章后面也会对Cookie做类似的处理。

- **Unicode编码：保存中文**

  - 中文与英文字符不同，**中文属于Unicode字符，在内存中占4个字符，而英文属于ASCII字符，内存中只占2个字节**。Cookie中使用Unicode字符时需要对Unicode字符进行编码，否则会乱码。

    提示：Cookie中保存中文只能编码。一般使用UTF-8编码即可。不推荐使用GBK等中文编码，因为浏览器不一定支持，而且JavaScript也不支持GBK编码。
  
- **Cookie文件的格式**

  - ![image-20210907223120546](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210907223120546.png)

  - ```markdown
    1. name				Cookie变量名
    2. value			Cookie变量值
    3. domain/			该Cookie变量所属域，形如csdn.net/、blog.csdn.net/或blog.csdn.net/lixianlin/
    4. 1600				可选标志
    5. 1263382784		该Cookie过期时间(FILETIME结构中的dwLowDateTime)
    6. 30020896			该Cookie过期时间(FILETIME结构中的dwHighDateTime)
    7. 452781968		该Cookie创建时间(FILETIME结构中的dwLowDateTime)
    8. 30020892			该Cookie创建时间(FILETIME结构中的dwHighDateTime)
    9. *				Cookie记录分隔符(为一个星号\*)
    ```


###### Session

```markdown
**
1. 什么是session？
	session，中文经常翻译为会话，其本来的含义是指有始有终的一系列动作/消息，比如打电话是从拿起电话拨号到挂断电话这中间的一系列过程可以称之为一个session。然而当session一词与网络协议相关联时，它又往往隐含了“面向连接”和/或“保持状态”这样两个含义。
	session在Web开发环境下的语义又有了新的扩展，它的含义是指一类用来在客户端与服务器端之间保持状态的解决方案。有时候Session也用来指这种解决方案的存储结构。
**
**
2.  Session的机制
	Session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构(也可能就是使用散列表)来保存信息。但程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否包含了一个session标识 —— 称为session id。
 > 如果已经包含一个session id则说明以前已经为此客户创建过session，服务器就按照session id把这个session检索出来使用(如果检索不到，可能会新建一个，这种情况可能出现在服务端已经删除了该用户对应的session对象，但用户人为地在请求的URL后面附加上一个JSESSION的参数)。
 > 如果客户请求不包含session id，则为此客户创建一个session并且生成一个与此session相关联的session id，这个session id将在本次响应中返回给客户端保存。
**
```

###### **==Cookie与Session的区别==**

**Cookie和Session都是用来跟踪浏览器用户身份的会话方式**，但是两者的应用场景不太一样。

- **Cookie一般用来保存用户信息**。比如①我们在Cookie中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你将登录的一些基本信息给填了；②一般的网站都会有保持登录，也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在Cookie中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。**Session的主要作用就是通过服务端记录用户的状态**。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为HTTP协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

- **有效期不同**，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。

- **Cookie数据保存在客户端(浏览器端)，Session 数据保存在服务器端。**

- **Cookie存储在客户端中，而Session存储在服务器上，相对来说Session安全性更高。**如果要在Cookie中存储一些敏感信息，不要直接写入Cookie中，最好能将Cookie信息加密然后使用到的时候再去服务器端解密。

  - ```markdown
    **
    > sessionid 是一个会话的 key，浏览器第一次访问服务器会在服务器端生成一个 session，有一个 sessionID 和它对应，并返回给浏览器，这个 sessionID 会被保存在浏览器的会话 cookie 中。tomcat 生成的 sessionID 叫做 jsessionID。
    ```

- 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

###### Token

**HTTP协议它是无状态的协议**，浏览器多次请求服务器，服务器它无法感知是不是同一用户的请求，于是就有了 `Session` 机制。若服务器做了负载均衡，用户的下一次请求可能会被定向到其它服务器节点，若那台节点上没有用户的Session信息，就会导致会话验证失败。**所以Session默认机制下是不适合分布式部署的**。

**Token的出现是为了解决Session的弊端**

Token我们一般称为令牌，一般通过MD5、SHA算法将密钥、公钥、时间戳等元素加密产生的加密字符串。

浏览器访问Web服务器后认证成功后生成Token并返回给客户端，客户端浏览器后续的请求都会把这个Token带到服务器端去验证，以此判定请求是否合法。

###### Session与Token的异同

**Session和Token机制原理上差不多，都是用户身份验证的一种识别手段**，它们都有过期时间的限制，但两者又有一些不同的地方。

1、**Session是存放在服务器端的，空间换时间的策略**，可以保存在：内存、数据库、NoSQL中。它采用空间换时间的策略来进行身份识别，若Session没有持久化落地存储，一旦服务器重启，Session数据会丢失。

2、**Token是放在客户端存储的**，采用了**时间换空间策略**，它**也是无状态的**，所以在分布式环境中应用广泛。

##### URI和URL的区别是什么

- URI(Uniform Resource Identifier)是统一资源标志符，可以唯一标识一个资源。
- URL(Uniform Resource Location)是统一资源定位符，可以提供该资源的路径。它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。

##### ==HTTP和HTTPS的区别==

> `HTTPS` 是一种应用层协议，本质上来说它是 `HTTP` 协议的一种变种。`HTTPS` 比 `HTTP` 协议安全，因为 `HTTP` 是明文传输，而 `HTTPS` 是加密传输，加密过程中使用了三种加密手段，分别是证书，对称加密和非对称加密。
>
> `HTTPS` 相比于 `HTTP` 多了一层 `SSL/TSL`。 `SSL(Secure Sockets Layer)` 安全套接字；`TLS(Transport Layer Security)`传输层安全协议。

**区别：**

1. 端口：`HTTP` 的 `URL` 由 “http:/∥”起始且默认使用端口 `80` ，而 `HTTPS` 的 `URL` 由“https:/∥”起始且默认使用端口 `443`。
2. 安全性和资源消耗：`HTTP` 协议运行在 `TCP` 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。`HTTPS` 是运行在 `SSL/TLS` 之上的 `HTTP` 协议，`SSL/TLS` 运行在 `TCP` 之上。所有传输的内容都经过加密，**加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密**。所以说，HTTP安全性没有HTTPS高，但是HTTPS比HTTP耗费更多服务器资源。
   - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；
   - 非对称加密：密钥成对出现(且根据公钥无法推知私钥，根据私钥也无法推知公钥)，加密解密使用不同密钥(公钥加密需要私钥解密，私钥加密需要公钥解密)，相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。

![HTTPS](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/bVp65j)



#####  HTTP1.0和HTTP1.1的主要区别是什么？

- **在HTTP/1.0中，默认使用的是短连接。**也就是说每次请求都要重新建立一次连接。在**HTTP/1.1中，默认使用长连接**，默认开启 `Connection: keep-alive` 。**HTTP/1.1的持续连接有非流水线方式和流水线方式**。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
- 在HTTP1.1中新增了24个错误状态响应码；如409(Conflict)表示请求的资源与资源的当前状态发生冲突；410(Gone)表示服务器上的某个资源被永久性的删除。
- 缓存处理：在HTTP1.0中主要使用header里的If-Modified-Since，Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since，If-Match，If-None-Match等更多可供选择的缓存头来控制缓存策略。
- 带宽优化及网络连接的使用：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206(Partial Content)，这样就方便了开发者自由的选择以便于充分利用带宽和连接。

##### HTTP1.1和 HTTP2.0的区别？

HTTP2.0相比HTTP1.1支持的特性：

- **新的二进制格式**：HTTP1.1 基于文本格式传输数据；HTTP2.0采用二进制格式传输数据，解析更高效。
- **多路复用**：在一个连接里，允许同时发送多个请求或响应，**并且这些请求或响应能够并行的传输而不被阻塞**，避免 HTTP1.1 出现的”队头堵塞”问题。
- **头部压缩**，HTTP1.1的header带有大量信息，而且每次都要重复发送；HTTP2.0 把header从数据中分离，并封装成头帧和数据帧，**使用特定算法压缩头帧**，有效减少头信息大小。并且HTTP2.0**在客户端和服务器端记录了之前发送的键值对，对于相同的数据，不会重复发送。**比如请求a发送了所有的头信息字段，请求b则**只需要发送差异数据**，这样可以减少冗余数据，降低开销。
- **服务端推送**：HTTP2.0允许服务器向客户端推送资源，无需客户端发送请求到服务器获取。

###### **HTTP1.0的长连接与HTTP2.0多路复用之间的区别？**

- **长连接：**同一个域名访问同一个文件的多个请求都可以复用一个tcp连接(不用像1.0一样 每次请求都需要重新建立连接)
  - 依然存在的问题：1.多个请求只能被串行处理(数据基于文本，只能按顺序传输)；2.访问多个不同的文件依然会建立多个请求。
- **多路复用：**同一个域名访问多个文件的请求也可以复用一个tcp连接，且多个请求可以被并行处理。
  - 并行实现原理：http2.0引入**二进制数据帧**和**流**的概念(数据帧对每一个数据进行标识，可以不按顺序传输，从而实现并行)。

##### HTTP 3.0

`QUIC (Quick UDP Internet Connections)`, 快速 UDP 互联网连接。

==`QUIC`是基于UDP协议的。==

两个主要特性：

**(1)线头阻塞(HOL)问题的解决更为彻底：**
基于TCP的HTTP/2.0，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输方面，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，则同样会阻塞在它之后传输的流数据传输。而基于UDP的QUIC协议则可以更为彻底地解决这样的问题，让不同的流之间真正的实现相互独立传输，互不干扰。

**(2)切换网络时的连接保持：**
当前移动端的应用环境，用户的网络可能会经常切换，比如从办公室或家里出门，WiFi断开，网络切换为3G或4G。基于TCP的协议，由于切换网络之后，IP会改变，因而之前的连接不可能继续保持。而基于UDP的QUIC协议，则可以内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。



![image-20210806122412122](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210806122412122.png)



#### ==14、HTTPS加密流程==

> 由于 `HTTP` 的内容在网络上实际是明文传输，并且也没有身份验证之类的安全措施，所以容易遭到挟持与攻击。
>
> `HTTPS` 是通过 **`SSL(安全套接层)` **和 **`TLS(安全传输协议)`**的组合使用，加密 `HTTP` 报文内容，同时通过不对称密钥方式认证身份，保证传输的安全可靠。 `
>
> 即：**HTTP+加密+认证+完整性保护=HTTPS**

##### 14.1、对称加密与非对称加密

> 对称加密: 编/解码使用相同密钥的算法,一般是共享密钥。
>
> ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1685507-20191101102728226-961172709.png)
>
> 常见的对称加密算法：`AES` 跟 `DES` 算法。

> 非对称加密: 非对称加密算法需要两个密钥，公开密钥(publickey:简称公钥)和私有密钥(privatekey:简称私钥)。 公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密。 因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法
>
> ![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1685507-20191101103037077-1478751442.png)
>
> 常见的非对称加密算法：`RSA`和`DSA`。

在HTTPS中，这两种加密方式混合使用。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1685507-20191101104105058-2077044780.png)

##### 14.2、数字证书认证

由于公钥在下发的时候也容易被替换劫持，所以需要个第三方认证机构确认公钥的正确性

CA：数字证书认证机构，是客户端服务端都认可的第三方机构，负责数字签名服务端公钥

数字签名：签名就是一种证明身份的机制，是一种校验机制(简单说是用私钥加密内容的hash,公钥解密对比hash判断内容是否完整)

数字证书：由一个可信的组织验证和签发的识别信息

HTTPS中数字认证流程如下

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1685507-20191101132559652-1495242555.png)

##### 14.3、HTTPS握手过程

HTTPS在进行传输HTTP报文数据前，需要经过TLS握手，完成加密，大致流程如下：

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1685507-20191031174134890-820879603.png)

- Client Hello:握手第一步是客户端向服务端发送 Client Hello 消息，这个消息里包含了一个客户端生成的随机数 Random1、客户端支持的加密套件(Support Ciphers)和 SSL Version 等信息
- Server Hello:第二步是服务端向客户端发送 Server Hello 消息，这个消息会从 Client Hello 传过来的 Support Ciphers 里确定一份加密套件，这个套件决定了后续加密和生成摘要时具体使用哪些算法，另外还会生成一份随机数 Random2。注意，至此客户端和服务端都拥有了两个随机数(Random1+ Random2)，这两个随机数会在后续生成对称秘钥时用到。
- Certificate:这一步是服务端将自己的证书下发给客户端，让客户端验证自己的身份，客户端验证通过后取出证书中的公钥
- Server Hello Done:通知客户端 Server Hello 过程结束。
- Certificate Verify:客户端收到服务端传来的证书后，先从 CA 验证该证书的合法性，验证通过后取出证书中的服务端公钥，再生成一个随机数 Random3，再用服务端公钥非对称加密 Random3生成 PreMaster Key
- Client Key Exchange:上面客户端根据服务器传来的公钥生成了 PreMaster Key，Client Key Exchange 就是将这个 key 传给服务端，服务端再用自己的私钥解出这个 PreMaster Key 得到客户端生成的 Random3。至此，客户端和服务端都拥有 Random1 + Random2 + Random3，两边再根据同样的算法就可以生成一份秘钥，握手结束后的应用层数据都是使用这个秘钥进行对称加密。为什么要使用三个随机数呢？这是因为 SSL/TLS 握手过程的数据都是明文传输的，并且多个随机数种子来生成秘钥不容易被暴力破解出来。
- Change Cipher Spec(Client):这一步是客户端通知服务端后面再发送的消息都会使用前面协商出来的秘钥加密了，是一条事件消息
- Encrypted Handshake Message(Client):这一步对应的是 Client Finish 消息，客户端将前面的握手消息生成摘要再用协商好的秘钥加密，这是客户端发出的第一条加密消息。服务端接收后会用秘钥解密，能解出来说明前面协商出来的秘钥是一致的
- Change Cipher Spec(Server):这一步是服务端通知客户端后面再发送的消息都会使用加密，也是一条事件消息
- Encrypted Handshake Message(Server):这一步对应的是 Server Finish 消息，服务端也会将握手过程的消息生成摘要再用秘钥加密，这是服务端发出的第一条加密消息。客户端接收后会用秘钥解密，能解出来说明协商的秘钥是一致的。
- Application Data:到这里，双方已安全地协商出了同一份秘钥，所有的应用层数据都会用这个秘钥加密后再通过 TCP 进行可靠传输

##### 14.4、其它

还有一种双向认证的模式,即在Server Hello Done前发送Certificate Request ，它是服务端要求客户端上报证书，这一步是可选的，对于安全性要求高的场景会用到，这里不做详解

如果每次重连都要重新握手还是比较耗时的，所以可以对握手过程进行优化，可以在 Client Hello 消息里还附带了上一次的 Session ID，服务端接收到这个 Session ID 后如果能复用就不再进行后续的握手过程

##### ==14.5、HTTPS加密的流程==

`HTTPS` 作为一种安全的应用层协议，它使用了证书加密、对称加密、非对称加密三种加密手段。

- 首先，**数据正文一般数据量较大，适用于对称加密**，因为对称加密速度快，适应于大量数据加密，但是安全级别低，其中对称加密的私钥需要在网络中传输，容易被盗取。

- 其次，正因为对称加密私钥易被盗取，所以我们需要对这个**私钥** 进行加密，而且安全级别要求高，所以这个可以用**非对称加密进行加密**，原因是对称加密的私钥数据量小，非对称加密可以提供高安全级别和高响应速度。

- 最后，由于 **非对称加密的公钥** 可以在网络中传输，如何保证公钥传送到给正确的一方，这个时候使用了**证书**来验证。证书不是保证公钥的安全性，而是验证正确的交互方。可以使用下图进行说明:

<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427193101884.png" alt="image-20210427193101884" style="zoom:80%;" />

```markdown
**
1. 客户端向服务器发起HTTPS的请求，连接到服务器的443端口；
2. 服务器将非对称加密的公钥传递给客户端，以证书的形式回传到客户端
3. 服务器接受到该公钥进行验证，就是验证第二步中的证书，如果有问题，则HTTPS请求无法继续；如果没有问题，则上述公钥是合格的。(第一次HTTP请求)客户端这个时候随机生成一个私钥，称为client key, 客户端私钥，用于对称加密数据的。使用前面的公钥对client key进行非对称加密；
4. 进行二次HTTP请求，将加密之后的client key传递给服务器；
5. 服务器使用私钥进行解密，得到client key, 使用client key对数据进行对称加密
6. 将对称加密的数据传递给客户端，客户端使用非对称解密，得到服务器发送的数据，完成第二次HTTP请求。
```

##### 14.6、SSL四次握手

HTTPS的通信步骤：

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/2020042800445749.png)

- **一次握手**
  - 客户端通过发送 Client Hello 报文开始 SSL通信。 报文中包含客户端支持的 SSL 的指定版本、 加密组件（Cipher Suite） 列表（所使用的加密算法及密钥长度等。
- **二次握手**
  - 服务器可进行 SSL 通信时， 会以 Server Hello 报文作为应答。 和客户端一样， 在报文中包含 SSL版本以及加密组件。 服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。
  - 之后服务器发送 Certificate 报文。 报文中包含公开密钥证书。
  - 最后服务器发送 Server Hello Done 报文通知客户端， 最初阶段的 SSL握手协商部分结束。
- **三次握手**
  - 客户端以 Client Key Exchange 报文作为回应。 报文中包含通信加密中使用的一种被称为 Pre-mastersecret 的随机密码串。 该报文已用步骤 3 中的公开密钥进行加密。
  -  接着客户端继续发送 Change Cipher Spec 报文。 该报文会提示服务器， 在此报文之后的通信会采用Pre-master secret 密钥加密。
  - 客户端发送 Finished 报文。 该报文包含连接至今全部报文的整体校验值。 这次握手协商是否能够成功， 要以服务器是否能够正确解密该报文作为判定标准。
- **四次握手**
  - 服务器同样发送 Change Cipher Spec 报文。
  - 服务器同样发送 Finished 报文。

总的来说，SSL会话的建立完成了以下几个工作：

> 交换协议版本号，选择一个通信双方都支持的加密方式；对两端实现身份验证；密钥交换。

************

#### 16、场景题

##### 16.1、打开一个网页，加载慢的原因？

- **带宽不足**：首先想到的就是自己网速的问题，但是一般网速在1M以上的，打开网页一般不会是很慢的。网站服务器的带宽不够的话，当大量用户访问的时候，网页的加载也是很慢的，这就是网络的出口端和入口端两个方面
- **硬件配置低**：本机的配置也会是一方面的，但是只要不是老赛扬单核+512M的配置，一般不会是电脑配置的问题。服务器端的配置也是同样的道理。
- **cpu或者内存是否被占满**：CPU或者是内存被占满的时候，打开网页很是会很慢的，因为整个电脑都很慢
- **DNS解析慢**：域名的解析是需要专门的域名解析服务器来完成的，DNS解析包括往复解析的次数及每次解析所花费的时间，它们两者的积即是DNS解析所耗费的总时间，在http请求的过程中，域名解析和建立连接占的时间很多。
- **JS阻塞请求**：写的js代码出现问题，解析就会花费很长时间，这两个js请求之间会出现一个很大的空隙，就会导致这段时间的资源加载都被阻塞住。
- **接收数据时间过长**：http请求的大部分时间应该花在后面几个阶段，比如等待响应和接收数据。但是，如果接收数据的时间太长了，长到数百毫秒甚至以秒计算的时候，那也是有问题的。这种情况一般是因为下载的内容太重了，例如大图片、大脚本等。这类问题可以使用GZIP压缩、图片压缩或者JS/CSS的minify等手段来解决。
- **加载某个资源过慢**：如果某个请求比其他的请求多出很多的时间，那么一般情况就是某个资源的加载太慢，导致了整个网页变慢，原因有可能是1)资源在第三方站点上，他们很慢；2)这个资源太大了；3)这个资源使用的域名有问题
- **后端代码问题**：主要有代码冗余、数据库发生锁死、动态请求时间过长等，这就需要RD优化一切可以优化的东西了
- **前端页面资源请求过多**：onload之前如果有几百行，速度自然会慢的，如果请求的资源不存在，那么速度将会更慢
- **网页本身包含了追踪或者分析用户的工具**：导致网页的加载时间变的慢，比如之前海盗湾中会给用户的电脑插入挖矿的js脚本

##### 16.2、向服务器申请一个网页，没有响应的原因？

- DNS坏掉了
- 网络断了
- 服务器拒绝访问
- 请求或者响应在网络中被劫走了

###### 别人能访问，自己不能访问

- 浏览器显示网络断开(没有网)
- 网页空白、服务器无法连接(原因很多：1、移动宽带无法正常访问其他线路的服务器，包括海外的；2、同IP现在或者曾经有对外攻击被对方服务器拒绝，电信有公网IP的用户在新的浏览器打开百度经常要输入验证码就是这个原因；3、你的肯定和服务器线路不够好，比如你访问的网站在国外，那么很多地区可以，很多地区不行；4、你主动请求服务器的特定网址或者FTP之类的服务产生了大量的链接请求，同原因②，你的IP地址被对方服务器记录，拒绝服务5、PPPOE)
- HTTPS导致(你在使用WindowsXP，或者使用Windows7但是并没有保持系统更新，无法访问相当一部分的HTTPS网站，比较常见的有京东)
- 偶尔能打开偶尔不能打开(服务器不够稳定，或者同原因2-4)

##### 16.3、为什么既需要ip地址，又需要mac地址？

**首先明确一点，并不是所有的网络之间传输数据都需要mac地址和ip地址，比如说点对点线路之间的通信就没有MAC地址，网络层使用ipx协议时就没有ip地址，但是在当前的主流网络中，我们都使用ip地址和mac地址。**

###### 16.3.1、既然mac地址唯一，为什么还要有IP地址?

之前我们提到，mac地址是唯一的，那理论上，在任何两个设备之间，我应该都可以通过mac地址发送数据，为什么还需要ip地址？

mac地址就好像个人的身份证号，人的身份证号和人户口所在的城市，出生的日期有关，但是和人所在的位置没有关系，人是会移动的，知道一个人的身份证号，并不能找到它这个人，mac地址类似，它是和设备的生产者，批次，日期之类的关联起来，知道一个设备的mac，并不能在网络中将数据发送给它，除非它和发送方的在同一个网络内。

所以要实现机器之间的通信，我们还需要有ip地址的概念，ip地址表达的是当前机器在网络中的位置，类似于城市名+道路号+门牌号的概念。通过ip层的寻址，我们能知道按何种路径在全世界任意两台Internet上的的机器间传输数据。

mac地址通常是不变的，ip地址是可变的，尤其是移动设备，ip地址会经常变更。

==mac地址的设计不携带设备在网络中的位置信息，想要通过mac地址通信，我们得在所有的设备上维护一张很大的表，记录所有mac地址路由在当前位置的的下一跳，这显然是不合理的。==

###### 16.3.2、既然能通过ip地址发送数据，为什么要有mac地址

既然ip地址有位置信息，而且在一个网络中也是唯一的，那么我们为什么不完全通过ip地址通信，抛弃mac地址呢？或者说，合并ip层和mac层的功能。

- **历史原因**
  最初的链路层协议是和ip地址无关的，没有网络层方面的设定，只有物理层和链路层，最初也只有集线器，没有交换机路由器，服务器之间传输数据全靠mac地址。在没有ip地址之前，mac地址已经在使用了。现在到处都在用的二层交换机，就是根据mac地址转发数据。
- **设计的原因**
  现在这样设计是好的设计，链路层的实现不需要考虑数据之间的转发，网络层的实现不需要考虑物层的影响。

也就是说，理论上可行，目前无太大意义，反而有坏处。

