### 数据库

****************

#### 1、常用数据库对比

| 数据库     | 优点                                                         | 缺点                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SQLite     | 轻量级；阔平台；                                             | 并发的读写方面性能不是很好；不支持SQL92标准                  |
| Oracle     | 1.Oracle的**稳定性**要比Sql server好。<br/>2.Oracle在导数据工具sqlload.exe功能比Sqlserver的Bcp功能强大,Oracle可以按照条件把文本文件数据导入.<br/>3.Oracle的**安全**机制比Sql server好。<br/>4.Sql server的**易用**性和友好性方面要比Oracle好。<br/>5.在处理大数据方面Oracle会更稳定一些。<br/>6.Sql Server在数据导出方面功能更强一些。<br/>7.处理速度方面比Oracle快一些，和两者的协议有关. | 价格**昂贵**                                                 |
| SQL Server | 1.真正的客户机/服务器体系结构<br/>2.图形化的用户界面，使系统管理和数据库管理更加直观、简单<br/>3.丰富的编程接口工具，为用户进行程序设计提供了更大的选择余地<br/>4.与WinNT完全集成，利用了NT的许多功能，如发送和接受消息，管理登录安全性等，**SQL** Server也可以很好地与Microsoft BackOffice产品集成。<br/>5.有很好的伸缩性，可以跨平台使用。<br/>6.提供数据仓库功能，这个功能只在Oracle和**其他**昂贵的DBMS中才有。 | 只能在**Windows**上运行；并行实施和共存模型并不成熟，很难处理日益增多的用户数和数据卷，**伸缩性有限**。 |
| MySQL      | 1.支持5000万条记录的数据仓库<br/>2.适应于**所有的平台**<br/>3.是**开源软件**，版本更新较快<br/>4.性能很出色。纯粹就性能而言，MySQL是相当出色的，因为它包含一个缺省桌面格式MyISAM。MyISAM数据库与磁盘非常地兼容而不占用过多的CPU和内存。MySQL可以运行于**Windows**系统而不会发生冲突，在UNIX或类似UNIX系统上运行则更好。你还可以通过使用64位处理器来获取额外的一些性能。因为MySQL在内部里很多时候都使用64位的整数处理。<br/>5.价格**便宜** | **缺乏一些存储程序**的功能，比如MyISAM引擎只支持交换功能。   |



#### 2、数据库常见死锁原因及处理

**产生死锁的原因主要是：**

（1）系统资源不足。

（2）进程运行推进的顺序不合适。

（3）资源分配不当等



虽然不能完全避免死锁，但可以使死锁的数量减至最少。将死锁减至最少可以增加事务的吞吐量并减少系统开销，因为只有很少的事务回滚，而回滚会取消事务执行的所有工作。由于死锁时回滚而由应用程序重新提交。

下列方法有助于最大限度地降低死锁：

（1）按同一顺序访问对象。

（2）避免事务中的用户交互。

（3）保持事务简短，并在一个批处理中。

（4）使用低隔离级别。

（5）使用绑定连接。

**********************

### 三大范式

**为什么需要数据规范化**

- 信息重复
- 更新异常
- 插入异常
  - 无法正常显示信息
- 删除异常
  - 丢失有效的信息



> **三大范式**

**第一范式(1NF)：要求数据库表的每一列都是不可分割的原子数据项**

![image-20210620100854713](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210620100854713.png)



**第二范式：确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）**

前提：满足第一范式；**在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）**

每张表只描述一件事情。

![image-20210620101356584](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210620101356584.png)



**第三范式：数据表中的每一列数据都和主键直接相关，而不能间接相关。**

前提：满足第一范式和第二范式；**2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）**

![image-20210620101749387](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210620101749387.png)

**规划性和性能的问题**

关联查询的表不得超过三张表

- 考虑商业化的需求和目标（成本、用户体验），数据库的性能更加重要。
- 在规范性能的问题的时候，需要适当的考虑一下 规范性！
- 故意给某些表增加一些荣誉的字段。【从多表查询变为单表查询】
- 故意增加一些计算列（从大数据量降低为小数据量）

**************

### MySQL

#### 1、什么是MySQL

​		MySQL是一种**关系型数据库**，在Java企业级开发中非常常用，因为MySQL是**开源免费的**，并且方便扩展。阿里巴巴数据库系统也大量用到了MySQL，因此它的**稳定性是有保障的**。MySQL是开放源代码的，因此任何人都可以在GPL（General Public License）的许可下下载并根据个性化的需要对其进行修改。MySQL的默认端口号是**3306**。

#### 2、存储引擎

###### 一些常用命令

**查看MySQL提供的所有存储引擎**

![image-20210412102225764](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412102225764.png)

从上图我们可以查看出MySQL当前默认的存储引擎是InnoDB，并且在5.7版本所有的存储引擎中只有InnoDB是事务性存储引擎，也就是说**只有InnoDB支持事务**。

**查看MySQL当前默认的存储引擎**

我们也可以通过下面的命令查看默认的存储引擎。

![image-20210412102312916](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412102312916.png)

**查看表的存储引擎**

![image-20210412102339770](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412102339770.png)

#### 3、MyISAM和InnoDB区别

​		MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，**但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。**不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。

大多数时候我们使用的都是InnoDB存储引擎，但是在某些情况下使用MyISAM也是合适的比如读密集的情况下。（如果你不介意MyISAM崩溃恢复问题的话）。

###### 二者的区别

1. **是否支持行级锁：**MyISAM只有表级锁（table-level locking），而InnoDB 支持行级锁（row-level locking）和表级锁，默认为行级锁。

   > 表锁虽然开销小，锁表快，但高并发下性能低。行锁虽然开销大，锁表慢，但高并发下相比之下性能更高。事务和行锁都是在确保数据准确的基础上提高并发的处理能力。

2. **是否支持事务和崩溃后的安全恢复：MyISAM强调的是性能**，每次查询具有原子性，其执行速度比InnoDB类型更快，但是不提供事务支持。但是**InnoDB提供事务支持事务**，外部键等高级数据库功能。具有事务（commit）、回滚（rollback）和崩溃修复能力（crash recoverycapabilities）的事务安全（transaction-safe（ACID compliant））型表。

3. **是否支持外键：**MyISAM不支持，而InnoDB支持。

4. **是否支持MVCC：**仅InnoDB支持。应对高并发事务，MVCC比单纯的加锁更高效；MVCC只在`READ COMMITTED`和`REPEATABLEREAD`两个隔离级别下工作；MVCC可以使用乐观（optimistic）锁和悲观（pessimistic）锁来实现；各数据库中MVCC实现并不统一。

> 不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

#### 4、字符集及校对规则

​		字符集指的是一种从二进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每一种字符集都会对应一系列的校对规则。

​		MySQL采用的是类似继承的方式指定字符集的默认值，每个数据库以及每张数据表都有自己的默认值，他们逐层继承。比如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采用默认字符集）。

#### ==5、索引==

**[MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)**

> MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的**数据结构**。	
>
> ```markdown
> 创建索引可以大大提高系统的性能。
> 1. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性;
> 2. 可以大大加快数据的检索速度，这也是创建索引的最主要的原因;
> 3. 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义;
> 4. 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间；第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能
> 
> **
> > B+树检索的事件复杂度: 
> 	层数log(m)n，每一层平均m/2，所以一共是(m/2) * log(m)n，由于m是常数，所以复杂度O(log n)，即以2为底n的对数
> 
> ```

MySQL索引使用的数据结构主要 **有BTree索引**和**哈希索引**。对于**哈希索引**来说，**底层的数据结构就是哈希表**，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

MySQL的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。

- **MyISAM: **B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。
- **InnoDB：**其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。** 

##### 5.1、索引为什么不是越多越好？

- 数据量小的表不需要建立索引，建立索引会增加额外开销；

- 数据变更需要维护索引，更多的索引要更多维护成本；

- 更多的索引需要更多的空间，因为索引需要空间来存放；


##### 5.2、索引的优点和缺点

**优点：**

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。  
- 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。      
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。   
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。   
- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

**缺点：**

- 创建索引和维护索引要耗费时间，这种时间随着数据 量的增加而增加。
- 索引需要占物理空间。除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
- 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数据的维护速度。

##### 5.3、判断SQL语句是否使用索引

使用 `explain` 关键字。

例如：

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20200328144924159.png)

###### 5.3.1、[`explain`的字段](https://blog.csdn.net/anthony4515/article/details/107959026)

**MYSQL 5.6.3**以前只能`EXPLAIN SELECT`; MYSQL5.6.3以后就可以`EXPLAIN SELECT,UPDATE,DELETE`。

![image-20210620214348813](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210620214348813.png)



##### 5.4、哪些列上创建索引

- 在经常需要搜索的列上，可以加快搜索的速度；  
- 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；  
- 在经常用在连接的列上，这 些列主要是一些外键，可以加快连接的速度；  
- 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；  
- 在经常需要排序的列上创 建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；  
- 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。

##### 5.5、B+树索引和哈希索引的区别

- 如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据;
- 如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
- 同理，哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
- 哈希索引也不支持多列联合索引的最左匹配规则；
- B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

##### 5.6、索引的类型及对比

- **主键索引**：一种特殊的唯一索引，不允许有空值。一般是在建表的时候指定了主键，就会创建主键索引。
- **唯一索引：**与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须一。
- **普通索引：**这是最基本的索引，它没有任何限制。

###### 5.6.1、索引数据结构的区别

- **主键索引的叶子节点存放的是整行数据( `InnoDB` 中的主键索引是一种聚簇索引)。**
- **普通索引与唯一索引的叶子节点存放的是主键索引的值**。辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。

###### 5.6.2、主键索引与唯一索引的其他区别

- 主键是一种约束，唯一索引是一种索引；
- 一张表只能有一个主键，但可以创建多个唯一索引；
- 主键创建后一定包含一个唯一索引，唯一索引并一定是主键；
- 主键不能为null，唯一索引可以为null；
- 主键可以做为外键，唯一索引不行。

###### 5.6.3、聚簇索引

​		聚簇索引就是按照每张表的主键构造一颗 `B+` 树，同时**叶子节点中存放的就是整张表的行记录数据**，也将聚簇索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，**每张表只能拥有一个聚簇索引**。

**聚簇索引不一定是唯一索引，聚簇索引的索引值并不要求是唯一的，唯一聚簇索引才是！在一个有聚簇索引的列上是可以插入两个或多个相同值的，这些相同值在硬盘上的物理排序与聚簇索引的排序相同，仅此而已。**

聚簇索引的顺序，就是数据在硬盘上的物理顺序。一般情况下主键就是默认的聚簇索引。

​		==`Innodb` 通过主键聚集数据，如果没有定义主键，`innodb` 会选择非空的唯一索引代替。如果没有这样的索引，`innodb`会隐式的定义一个主键来作为聚簇索引。==

**优点：**

- 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快。
- 聚簇索引对于主键的排序查找和范围查找速度非常快。

**缺点：**

- 插入速度严重依赖于插入顺序，按照主键的**顺序插入**是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于`InnoDB` 表，我们一般都会定义一个**自增的ID列为主键**
- **更新主键的代价很高**，因为将会导致被更新的行移动。因此，对于 `InnoDB` 表，我们**一般定义主键为不可更新。**
- 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

###### 5.6.4、非聚簇索引

​		辅助索引访问数据总是需要二次查找。**辅助索引叶子节点存储的不再是行的物理位置，而是主键值**。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的 `Page Directory` 找到数据行。

　　`Innodb` 辅助索引的叶子节点并**不包含行记录的全部数据**，叶子节点除了包含键值外，还包含了相应行数据的聚簇索引键。

　　辅助索引的存在不影响数据在聚簇索引中的组织，所以**一张表可以有多个辅助索引**。在 `innodb` 中有时也称辅助索引为二级索引。

##### 5.7、覆盖索引

覆盖索引（covering index）指一个查询语句的执行只用从索引页中就能够取得（如果不是聚集索引，叶子节点存储的是主键+列值，最终还是要回表，也就是要通过主键再查找一次），避免了查到索引后，再做回表操作，减少I/O提高效率。

用唯一键或者隐藏列代替索引。

- 解释一： 就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。
- 解释二： 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做 覆盖索引。
- 解释三：是非聚集组合索引的一种形式，它包括在查询里的Select、Join和Where子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数）。

　　不是所有类型的索引都可以成为覆盖索引。覆盖索引必须要存储索引的列，而哈希索引、空间索引和全文索引等都不存储索引列的值，所以MySQL只能使用B-Tree索引做覆盖索引

　　当发起一个被索引覆盖的查询(也叫作索引覆盖查询)时，在 `EXPLAIN的Extra` 列可以看到 `Using index` 的信息

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1254583-20171013140305355-620036288.png)

从执行结果上看，这个SQL语句只通过索引，就取到了所需要的数据，这个过程就叫做索引覆盖。



##### ==5.8、索引底层实现，为什么使用B+树==

**B+树的特性如下：**

- 有n棵子树的非叶子结点中含有n个关键字（b树是n-1个），这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接(使用的是 **双向链表**)。
- 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- 通常在b+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点。
- 同一个数字会在不同节点中重复出现，根节点的最大元素就是b+树的最大元素。
- 更适合文件索引系统

一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。

**为什么使用B+树**

索引查找过程中就要用到产生磁盘I/O消耗，主要看I/O次数，和磁盘存取原理有关。

**根据B-Tree的定义，可知检索一次最多需要访问h（树高）个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。**

要考虑磁盘IO的影响，它相对于内存来说是很慢的。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少IO次数，对于树来说，IO次数就是树的高度，而“矮胖”就是b树的特征之一，它的每个节点最多包含m个孩子，m称为b树的阶，m的大小取决于磁盘页的大小。

###### 5.8.1、B+树与红黑树的比较

红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用B+树作为索引结构，这是因为B+树访问磁盘数据有更高的性能。

- B+树高更低
  - 平衡树的树高 $O(h)=O(log_dN)$，其中 $d$ 为每个结点的出度。红黑树的出度为 $2$，而B+树的出度一般非常大，所以红黑树的树高 $h$ 很明显比B+树大非常多。
- 磁盘访问原理
  - 操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。
  - 如果数据不在同一个磁盘块上，那么需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致移动效率低下。B+树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以B+树适合磁盘数据的读取。
- 磁盘预读特性
  - 为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度非常快。并且可以利用预读特性，相邻的结点也能够被预先载入。

###### 5.8.2、B+树相比于B树的查询优势

1. B+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”；
2. B+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）；
3. 对于范围查找来说，因为B+树每个叶子节点都有一个指向相邻叶子节点的指针, b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历.

###### 5.8.3、MySQL数据库的索引是在哪一层实现的

在MySQL中索引是在 **存储引擎层** 实现的，而不是在服务器层实现的。**不同存储引擎实现索引的方式也各有不同**。

##### 5.9、MySQL为什么不用哈希表

Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B+Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B+Tree 索引。

可能很多人又有疑问了，既然 Hash 索引的效率要比 B+Tree 高很多，为什么大家不都用 Hash 索引而还要使用 B+Tree 索引呢？任何事物都是有两面性的，Hash 索引也一样，虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些：

- **Hash 索引仅仅能满足”=”,”IN”和”<=>”查询，不能使用范围查询。**由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
- **Hash 索引无法被用来避免数据的排序操作。**由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
- **Hash 索引不能利用部分索引键查询。**对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
- **Hash 索引在任何时候都不能避免表扫描。**前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
- **Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B+Tree索引高。**对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。

##### 5.10、`InnoDB` 与 `MyISAM` 建索引的区别

- `InnoDB` 中，主键索引用的是聚簇索引，聚簇索引跟辅助索引叶子节点中存储的值是不同的；
- `MyISAM`中不管是主键索引还是别的索引形式都是一样的。

###### MyISAM索引实现

**1. 主键索引**

`MyISAM` 引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20150527164101257)

这里设表一共有三列，假设我们以Col1为主键，则上图是一个`MyISAM`表的主索引（Primary key）示意。可以看出`MyISAM`的索引文件仅仅保存数据记录的地址。在`MyISAM`中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：

**2. 辅助索引**

**在`MyISAM`中，主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。**下图在Col2上建立一个辅助索引。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/679616-20180115165735474-330858823.png)

同样也是一颗B+Tree，data域保存数据记录的地址。因此，**MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。**

MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

###### InnoDB索引实现

**1 主键索引**

`InnoDB` 表数据文件本身就是一个索引结构，树的叶节点data域保存了完整的数据记录，这种索引叫做**聚集索引**。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/679616-20180115170146521-491912290.png)

上图是 `InnoDB `主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为 `InnoDB `的数据文件本身要按主键聚集，所以 `InnoDB `要求表必须有主键（`MyISAM`可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为`InnoDB`表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。

**2 辅助索引(二级索引)**

`InnoDB` 的辅助索引的**叶子结点存储的是主键而不是数据**。换句话说，**`InnoDB` 的所有辅助索引都引用主键作为data域。**下图为定义在Col3上的一个辅助索引。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/679616-20180115170511553-101534877.png)

**聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。**

###### 总结

**`InnoDB` 的数据文件本身就是主索引文件。而 `MyISAM` 的主索引和数据是分开的。**

**`InnoDB `的辅助索引的叶子节点存储的是相应记录主键的值而不是地址。而`MyISAM`的辅助索引和主索引没有多大区别**

###### 回表查询

```markdown
**
非主键索引查找数据时需要先找到主键，再根据主键查找具体的行数据，这种现象叫回表查询。
```

**如何避免**

```markdown
# 简历索引覆盖，即将查询sql中的字段添加到联合索引里面，只要保证查询语句里面的字段都在索引文件中，就无需进行回表查询；
```

***************

##### 5.11、MySQL联合索引最左匹配原则

###### 联合索引

对列col1、列col2和列col3建一个联合索引：

```mysql
KEY test_col1_col2_col3 on test(col1,col2,col3);
```

联合索引 `test_col1_col2_col3` 实际建立了 `(col1)、(col1,col2)、(col,col2,col3)` 三个索引。

**注意：索引的字段是任意顺序的**

```mysql
SELECT * FROM test WHERE col1=“1” AND clo2=“2”
SELECT * FROM test WHERE col2=“2” AND clo1=“1”
```

这两个查询语句都会用到索引 `(col1,col2)`，`MySQL`创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段 `col1 `的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段 `col2` 进行排序。其实就相当于实现了类似 `order by col1, col2`这样一种排序规则。

有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引` (col1,col2)` 中的 `col1、col2` 两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助 `MySQL`查询优化器 `explain`，`explain`会纠正 `sql` 语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。

**为什么要使用联合索引**

- **减少开销**。建一个联合索引 `(col1,col2,col3)`，实际相当于建了` (col1),(col1,col2),(col1,col2,col3)` 三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
- **覆盖索引**。对联合索引 `(col1,col2,col3)`，如果有如下的 `sql: select col1,col2,col3 from test where col1=1 and col2=2`。那么`MySQL`可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 `IO` 操作。减少 `IO` 操作，特别的随机 `IO` 其实是数据库管理员主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
- **效率高**。索引列越多，通过索引筛选出的数据越少。有 `1000W` 条数据的表，有如下 `sql: select * from table where col1=1 and col2=2 and col3=3`, 假设每个条件可以筛选出 `10%` 的数据。如果只有单值索引，那么通过该索引能筛选出 `1000W * 10% = 100w` 条数据，然后再回表从 `100w` 条数据中找到符合 `col2=2 and col3=3 ` 的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出 `1000w * 10% * 10% * 10% = 1w` ，效率提升可想而知。

###### 最左匹配原则

**定义：**最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(`>、<、between、like`)就会停止匹配。

- 例如：`b = 2` 如果建立 `(a,b)` 顺序的索引，是匹配不到 `(a,b)` 索引的；
- 但是如果查询条件是`a = 1 and b = 2`或者 `a=1` (又或者是`b = 2 and b = 1`)就可以，因为优化器会自动调整a,b的顺序。
- 再比如`a = 1 and b = 2 and c > 3 and d = 4` 如果建立 `(a,b,c,d)` 顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配。

**最左匹配原则的原理**

​	最左匹配原则都是针对联合索引来说的，所以我们有必要了解一下联合索引的原理。了解了联合索引，那么为什么会有最左匹配原则这种说法也就理解了。

​	索引的底层是一颗B+树，那么**联合索引当然还是一颗B+树**，**只不过联合索引的健值数量不是一个，而是多个**。构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。

例子：假如创建一个`(a,b)` 的联合索引，那么它的索引树是这样的：

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/1281680-20190117145740508-758737271.png)

可以看到a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。同时我们还可以发现在a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。**这是因为MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后才对第二个字段进行排序。**所以 `b = 2` 这种查询条件没有办法利用索引，因为联合索引首先是按 a 排序的，b是无序的。

所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。例如 `a = 1 and b = 2`, `a,b` 字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而 `a>1 and b=2 `，`a` 字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。

***********

##### 5.12、查询缓存的使用

> 执行查询语句的时候，会先查询缓存。不过，MySQL 8.0版本后移除，因为这个功能不太实用。

`my.cof`加入以下缓存，重启MySQL开启查询缓存

![image-20210412103346237](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412103346237.png)

MySQL执行以下命令也可以开启查询缓存

![image-20210412103354231](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412103354231.png)

​		如上，**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。**这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。因此任何两个查询在任何字符上的不同都会导致缓存不命中。此外，如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果也不会被缓存。

​		缓存建立之后，MySQL的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。

​		**缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。**因此，开启缓存查询要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十MB比较合适。此外，**还可以通过sql_cache和sql_no_cache来控制某个查询语句是否需要缓存：**

![image-20210412103604258](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412103604258.png)

*****************

##### 5.13、为什么使用索引以后查询速度变快

​	   索引就相当于一本书的目录，通过目录来找书中的某一页，确实是很快的，如果没有目录，就需要一页一页的去翻书了，大大降低了效率。这个比喻其实还挺恰当的，也是一个很经典的索引比喻了。

##### 5.14、缓存失效

```markdown
**
1. 违反最左匹配原则
	最左匹配原则：最左优先，以最左边的为起点任何连续的索引都能匹配上，如不连续，则匹配不上。
	1.1 如：建立索引为(a,b)的联合索引，那么只查 where b = 2 则不生效。换句话说：如果建立的索引是(a,b,c)，也只有(a),(a,b),(a,b,c)三种查询可以生效。
	1.2 遇到范围查询（>、<、between、like）就会停止匹配。
2. 在索引列上做任何操作
	如计算、函数、（手动或自动）类型转换等操作，会导致索引失效而进行全表扫描。
	explain select * from user where left(name,3) = 'zhangsan' and age =20
3. 使用不等于（!= 、<>）
4. like中以通配符开头('%abc')
	4.1 索引失效：explain select * from user where name like ‘%zhangsan’;
	4.2 索引生效：explain select * from user where name like ‘zhangsan%’;
5. 字符串不加单引号索引失效 
	explain select * from user where name = 2000;
6. or连接索引失效
	explain select * from user where name = ‘2000’ or age = 20 or pos =‘cxy’;
**
```

****************

#### ==6、MySQL MVCC==

##### 6.1、什么是MVCC?

> **`MVCC`**，全称`Multi-Version Concurrency Control`，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。
>
> **`MVCC`** 在 **`MySQL InnoDB`** 中的实现主要是为了**提高数据库并发性能**，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

```markdown
**
1. 多版本并发控制（MVCC） 是通过`保存数据在某个时间点的快照`来实现并发控制的。也就是说，不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。
2. 简单来说，多版本并发控制 的思想就是`保存数据的历史版本`，通过对数据行的多个版本管理来实现数据库的并发控制。这样我们就可以`通过比较版本号决定数据是否显示出来`，读取数据的时候不需要加锁也可以保证事务的隔离效果。
```

##### 6.2、什么是当前读和快照读？

- **当前读**
  
  - ```mysql
    # 对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式
    select * from table where ? lock in share mode; 
    select * from table where ? for update; 
    insert; 
    update; 
    delete;
    ```
  
  - 像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它**读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁**。
  
- **快照读**

  - ```mysql
    # 我们平时只用使用select就是快照读,这样可以减少加锁所带来的开销.
    select * from table ....
    ```

  - 像==不加锁==的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即**快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。**

> **MVCC就是为了实现读-写冲突不加锁，而这个读指的就是==快照读==, 而非==当前读==，==当前读==实际上是一种加锁的操作，是悲观锁的实现**。 `InnoDB ` 的 `MVCC `采用的是乐观锁的方式。

##### 6.3、当前读，快照读和MVCC的关系

- 准确的说，`MVCC` 多版本并发控制指的是 “**维持一个数据的多个版本，使得读写操作没有冲突**” 这么一个概念。仅仅是一个理想概念
- 而在MySQL中，**实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。**而相对而言，当前读就是悲观锁的具体功能实现
- 要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 3个隐式字段，undo日志 ，Read View 等去完成的，具体可以看下面的MVCC实现原理。

##### 6.4、MVCC的实现原理

MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决`读写冲突`，它的实现原理主要是依赖记录中的 **`3个隐式字段`**，**`undo log`** ，**`Read View`** 来实现的。

###### 6.4.1、**隐式字段**

MySQL每行记录除了我们自定义的字段外，还有数据库隐式定义的`DB_TRX_ID`,`DB_ROLL_PTR`,`DB_ROW_ID`等字段。

- **`DB_TRX_ID`(事务ID)**
  6byte，最近修改(`修改/插入`)事务ID：记录创建这条记录/最后一次修改该记录的事务ID。
- **`DB_ROLL_PTR`(回滚指针)**
  7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
- **`DB_ROW_ID`(隐藏主键)**
  6byte，隐含的自增ID（`隐藏主键`），如果数据表没有主键，`InnoDB` 会自动以 `DB_ROW_ID `产生一个聚簇索引
- 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了。

![image-20210515185850039](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210515185850039.png)

`DB_ROW_ID`是数据库默认为该行记录生成的唯一隐式主键，`DB_TRX_ID`是当前操作该记录的事务ID, 而`DB_ROLL_PTR`是一个回滚指针，用于配合undo日志，指向上一个旧版本。

###### 6.4.2、**undo日志**

undo log主要分为两种：

- **insert undo log**

  代表事务在 `insert `新记录时产生的 `undo log`, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃。

- **update undo log**
  事务在进行 `update `或 `delete `时产生的 `undo log`; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除。

<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/view">

​		从图中能看到回滚指针将数据行的所有快照记录都通过链表的结构串联了起来，每个快照的记录都保存了当时的 `db_trx_id`，也是那个时间点操作这个数据的**事务 ID**。这样如果我们想要找历史快照，就可以通过遍历回滚指针的方式进行查找。

###### 6.4.3、**Read View(读视图)**

Read View就是事务进行`快照读`操作的时候生产的`读视图`(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(**当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大**)。

 `Read View`主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个`Read View`读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的`undo log`里面的某个版本的数据。

`Read View`遵循一个可见性算法，主要是将要被修改的数据的最新记录中的`DB_TRX_ID`（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由`Read View`维护），如果`DB_TRX_ID`跟`Read View`的属性做了某些比较，不符合可见性，那就通过`DB_ROLL_PTR`回滚指针去取出`Undo Log`中的`DB_TRX_ID`再比较，即遍历链表的`DB_TRX_ID`（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, **那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本。**

##### 6.5、MVCC能否解决幻读的问题？

在 `InnoDB` 中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是**事务的版本号**，每开启一个新事务，事务的版本号就会递增。 在可重读 `Repeatable Read` 事务隔离级别下：

- `SELECT` 时，读取创建版本号<=当前事务版本号，删除版本号为空或>当前事务版本号。
- `INSERT` 时，保存当前事务版本号为行的创建版本号
- `DELETE` 时，保存当前事务版本号为行的删除版本号
- `UPDATE` 时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行
- ![mvcc](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/mvcc.png)



**一般来说是可以解决幻读**

**下面是不能解决的情况：**

![specialcase](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/specialcase.png)

1.a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意操作），
	2.a事务再select出来的结果在MVCC下还和第一次select一样，
	3.接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的)，
	4.a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了.

##### 6.6、RC 、RR 级别下的MVCC有什么不同？

```markdown
**
#  在 RR 级别下的某个事务的对某条记录的第一次快照读会创建一个快照及 Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个 Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个 Read View，所以对之后的修改不可见；即 RR 级别下，快照读生成 Read View 时，Read View 会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见。`这是mvcc实现可重复读的关键，即使其他事务commit，但由于read view还是第一次select时生成的那个，所以当前事务还是看不到`

#  在 RC 级别下的事务中，每次快照读都会新生成一个快照和 Read View , 这就是我们在 RC 级别下的事务中可以看到别的事务提交的更新的原因。
**
- 在 RC(读取已提交) 隔离级别下，是每个快照读都会生成并获取最新的 Read View
- 在 RR(可重复读) 隔离级别下，则是同一个事务中的第一个快照读才会创建 Read View, 之后的快照读获取的都是同一个 Read View。
```



#### 7、MySQL主从复制

##### 7.1、主从复制

> **过程：**
>
> 主数据库开启 `bin-log` 功能，日志文件用于记录数据库的读写增删；
>
> 需要开启3个线程，主数据库开启 IO线程，从数据库开启 IO线程 SQL线程，
>
> 从数据库 通过 IO 线程连接主数据库，并且请求某个 `bin-log`，position之后的内容。
> 主服务器收到从服务器 IO线程发来的日志请求信息，IO线程去将 `bin-log`内容，position返回给从数据库 IO 线程。
> 从服务器收到 `bin-log` 日志内容，将 `bin-log`  日志内容写入`relay-log` 中继日志，创建一个 `master.info` 的文件，该文件记录了master ip 用户名 密码 master bin-log名称，bin-log position。
> 从数据库端开启SQL线程，实时监控 `relay-log` 日志内容是否有更新，解析文件中的SQL语句，在从数据库中去执行。
>
> ****************
>
> DML（data manipulation language）：
> 它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言
> 		DDL（data definition language）：
> DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用
> 		DCL（Data Control Language）：
> 是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。在默认状态下，只有sysadmin,dbcreator,db_owner或db_securityadmin等人员才有权力执行DCL

##### 7.2、基本原理

​		MySQL支持单向、异步复制，复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。

　　MySQL复制是基于主服务器在二进制日志中跟踪所有对数据库的更改。因此，要进行复制，必须在主服务器上启用二进制日志。每个从服务器 从主服务器接收主服务器已经记录到日志的数据。

　　当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，并在本机上执行相同的更新。然后封锁并等待主服务器通知新的更新。从服务器执行备份不会干扰主服务器，在备份过程中主服务器可以继续处理更新。 

> 1)、在master机器上的操作：
> 　 当master上的数据发生变化时，该事件变化会按照顺序写入bin-log中。当slave链接到master的时候，master机器会为slave开启binlog dump线程。当master的binlog发生变化的时候，bin-log dump线程会通知slave，并将相应的binlog内容发送给slave。
> 2)、在slave机器上操作：
>
> 　 当主从同步开启的时候，slave上会创建两个线程：I\O线程。该线程连接到master机器，master机器上的binlog dump 线程会将binlog的内容发送给该I\O线程。该I/O线程接收到binlog内容后，再将内容写入到本地的relay log；sql线程。该线程读取到I/O线程写入的ralay log。并且根据relay log。并且根据relay log 的内容对slave数据库做相应的操作。

>  三种主要实现粒度
> 详细的主从同步主要有三种形式：statement、row、mixed
> 　1)、statement: 会将对数据库操作的sql语句写道binlog中
> 　2)、row: 会将每一条数据的变化写道binlog中。
>   3)、mixed: statement与row的混合。Mysql决定何时写statement格式的binlog, 何时写row格式的binlog

##### 主从复制的作用

　	1、主数据库出现问题，可以切换到从数据库。

　　2、可以进行数据库层面的读写分离。

　　3、可以在从数据库上进行日常备份。

##### 复制过程

![image-20210427213141809](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427213141809.png)

*Binary log：主数据库的二进制日志。*

*Relay log：从服务器的中继日志。*

**第一步：**master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

**第二步：**salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

**第三步：**SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

##### 主从复制延迟的原因

![image-20210427213834516](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210427213834516.png)

1)、MySQL数据库主从同步延迟原理：主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。有朋友会问：“主库上那个相同的DDL也需要执行10分，为什么slave会延时？”，答案是master可以并发，Slave_SQL_Running线程却不可以。

2)、MySQL数据库主从同步延迟是怎么产生的？当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。

**首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高。**

**次要原因：读写binlog带来的性能影响，网络传输延迟。**

**********

#### ==8、什么是事务？==

**事务是逻辑上的一组操作，要么都执行，要么都不执行。**

​		事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

当数据库需要处理操作量大、复杂度高的数据的时候需要用到事务。(不知道这句话对不对，记得百度二面的时候被质疑了)

##### 8.1、事务的四大特性（ACID）

![image-20210412103738548](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412103738548.png)

- **原子性（Atomicity）：**事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
  - 例子：A给B转账，A减少200元，B增加200元。必须全部完成。不能只存在A的金额减少或者B的金额增加的情况。
- **一致性（Consistency）：**执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
  - 操作前 A：800，B：200；操作后 A：600，B：400。总金额：1000元。
- **隔离性（lsolation）：**并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
  - A在给B转账的同时，C也在给B转账，两者互不干扰。
- **持久性（Durability）：**一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
  - 例子：
    - 操作前 A：800，B：200
    - 操作后 A：600，B：400
    - 如果**事务还没有提交**服务器宕机或者断电，那么重启数据库以后，数据状态应该为A：800，B：200.
    - 如果**事务提交以后**服务器宕机或者断电，那么重启数据库以后，数据状态应该为A：600，B：400.

##### 8.2、并发事务带来哪些问题？

在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

- **脏读（Dirty read）：**当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
  - ![脏读](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/%E8%84%8F%E8%AF%BB.png)
- **丢失修改（Lost to modify）**：指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
- **不可重复读（Unrepeatable read）：**指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
  - ![不可重复读](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png)
- **幻读（Phantom read）：**幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
  - ![幻读](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/%E5%B9%BB%E8%AF%BB.png)

**不可重复读和幻读区别：**

不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

##### 8.3、事务隔离界别有哪些？

**SQL标准定义了四个隔离级别：**

- **READ-UNCOMMITTED（读取未提交）：**最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
  - 事务2更新id=1的数据后,仍然允许事务1读取该条数据,所以事务1第二次执行查询,读到了事务2更新的结果,产生了脏读.
  - ![image-20210806090248618](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210806090248618.png)
- **READ-COMMITTED（读取已提交）：** **允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行,会对该写锁一直保持直到到事务提交**.，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
  - **脏读：**事务2更新id=1的数据后,在提交前,会对该对象写锁,所以事务1读取id=1的数据时,会一直等待事务2结束,处于阻塞状态,避免了产生脏读.
  - **不可重复读：**事务1读取id=1的数据后并没有锁住该数据,所以事务2能对这条数据进行更新,事务2对更新并提交后,该数据立即生效,所以事务1再次执行同样的查询,查询到的结果便与第一次查到的不同,所以已提交读**防不了不可重复读**。
- **REPEATABLE-READ（可重复读）：**对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- **SERIALIZABLE（可串行化）：**最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

![image-20210412104437650](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412104437650.png)

MySQL InnoDB存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过 `SELECT @@tx_isolation; `命令来查看：

![image-20210412104615932](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412104615932.png)

这里注意的是：与SQL标准不同的地方在于InnoDB存储引擎默认在**REPEATABLE_READ(可重读)**上。

事务隔离级别下使用的是`Next-Key Lock `锁算法，因此可以避免幻读的产生，这与其他数据库系统（如SQL Server）是不同的。

> - **产生幻读的原因：**行锁只能锁住一行，不能避免新插入的记录；
>
> - **解决幻读**：在两行记录之间加上间隙锁，阻止新纪录的插入，与间隙锁产生冲突的只有“往这个间隙插入记录”这个操作；
> - 同时添加间隙锁与行锁称为**Next-key lock**，注意间隙锁只有在InnoDB的可重复读隔离级别下生效；

所以说InnoDB存储引擎的默认支持的隔离级别是**REPEATABLE-READ（可重读）**已经可以完全保证事务的隔离性要求，即达到了SQL标准的**SERIALIZABLE（可串行化）**隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是**READ-COMMITTED（读取提交内容）**，但是你要知道的是InnoDB存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。

InnoDB存储引擎在**分布式事务**的情况下一般会用到**SERIALIZABLE(可串行化) **隔离级别。

**设置MySQL的隔离级别**

```mysql
set session transaction isolation level 隔离级别;

# 比如设置read uncommitted级别
set session transaction isolation level read uncommitted;
```



###### 8.3.1、MySQL如何解决幻读？

- 在快照读读情况下，`MySQL` 通过 [MVCC](#####6.5、MVCC能否解决幻读的问题？) 来避免幻读。
- 在当前读读情况下，`MySQL` 通过 **`next-key`锁** 来避免幻读

##### 8.4、MySQL的回滚机制

> 在 MySQL 中，**回滚机制**是通过**回滚日志（``undo log`）**实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。
>
> **`undo log`**是记录了sql执行语句的反向逻辑，比如：执行一条INSERT语句，就在undo log记录一条逻辑相反的DELETE语句；执行一条UPDATE语句，就记录一条能恢复原数据的UPDATE语句。当事务回滚后，就能恢复到初始的数据状态。

MySQL的事务是有 `redo` 和 `undo` 的，**`redo`操作的所有信息都是记录到 `redo_log`中，也就是说当一个事务做`commit`操作时，需要先把这个事务的操作写到 `redo_log` 中，然后再把这些操作 `flush` 到磁盘上，当 出现故障时，只需要读取 `redo_log` , 然后再重新 flush 到磁盘就行了。**

而对于undo就比较麻烦，MySQL在处理事务时，会在数据共享 表空间里申请一个段叫做segment段，用保存undo信息，当在处理rollback，不是完完全全的物理undo，而是逻辑undo, 就是说会对之前的操作进行反操作，但是这些共享表空间是不进行回收的。这些表空间的回收需要由mysql的master thread进程来进行回收。

###### 8.4.1、MySQL中是如何实现事务提交和回滚的？

为了保证数据的持久性，数据库在执行SQL操作数据之前会先记录redo log(重做日志)和undo log(回滚日志)

- redo log是重做日志，通常是物理日志，记录的是物理数据页的修改，它用来恢复提交后的物理数据页
- undo log是回滚日志，用来回滚行记录到某个版本，undo log一般是逻辑日志，根据行的数据变化进行记录
- redo/undo log都是写先写到日志缓冲区，再通过缓冲区写到磁盘日志文件中进行持久化保存
- undo日志还有一个用途就是用来控制数据的多版本（MVCC）

简单理解就是：

**redo log是用来恢复数据的，用于保障已提交事务的持久性**

**undo log是用来回滚事务的，用于保障未提交事务的原子性**

****************************

##### 8.5、MySQL如何实现事务的？

等同于：**MySQL如何保证原子性(`undo log`)，一致性，持久性(`redo log`)**。

###### **原子性**

MySQL事务的**原子性**是通过 `undo log` 来实现的。`undo log` 是 `InnoDB` 存储引擎特有的。具体的实现方式是：将所有对数据的修改（增、删、改）都写入日志（`undo log`）。如果一个事务中的一部分操作已经成功，但另一部分操作，由于断电/系统崩溃/其它的软硬件错误而无法成功执行，则通过回溯日志，将已经执行成功的操作撤销，从而达到全部操作失败的目的。

**`undo log` 是逻辑日志，可以理解为：记录和事务操作相反的SQL语句**，事务执行 `insert` 语句，`undo log` 就记录`delete` 语句。它以追加写的方式记录日志，不会覆盖之前的日志。除此之外 `undo log` 还用来实现数据库多版本并发控制（`Multiversion Concurrency Control`，简称 `MVCC`）。

###### **持久性**

MySQL事务的 **持久性** 是通过 `redo log` 来实现的。`redo log` 也是 `InnoDB` 存储引擎特有的。具体实现方式是：当发生数据修改（增、删、改）的时候，`InnoDB` 引擎会先将记录写到 `redo log` 中，并更新内存，此时更新就算完成了。同时InnoDB引擎会在合适的时机将记录刷到磁盘中。

**`redo log` 是物理日志，记录的是在某个数据页做了什么修改，而不是SQL语句的形式。**它有固定大小，是循环写的方式记录日志，空间用完后会覆盖之前的日志。



`undo log`和`redo log`并不是直接写到磁盘上的，而是先写入`log buffer`。再等待合适的时机同步到`OS buffer`，再由操作系统决定何时刷到磁盘，具体过程如下：

<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20200425210059474.jpg" style="zoom:70%">

既然 `undo log` 和 `redo log` 都是从 `log buffer` 到 `OS buffer`，再到磁盘。所以中途还是有可能因为断电/硬件故障等原因导致日志丢失。为此**MySQL提供了三种持久化**方式，一个参数 `innodb_flush_log_at_trx_commit`，这个参数主要控制 `InnoDB` 将 `log buffer` 中的数据写入 `OS buffer` ，并刷到磁盘的时间点，取值分别为 `0，1，2` ，默认是1。这三个值的意思分别如下:

<img src="https://gitee.com/yun-xiaojie/blog-image/raw/master/img/20200308212726564.jpg" style="zoom:70%">

首先查看MySQL默认设置的方式1，也就是每次提交后直接写入`OS buffer`，并且调用系统函数`fsync()`把日志写到磁盘上。就保证数据一致性的角度来说，这种方式无疑是最安全的。但是我们都知道，**安全大多数时候意味着效率偏低**。每次提交都直接写入 `OS buffer`并且写到磁盘，无疑会导致单位时间内 IO 的次数过多而效率低下。除此之外，还有方式0和方式2。基本上都是每秒写入磁盘一次，所以效率都比方式1更高。但是方式0是把数据先写入 `log buffer` 再写入 `OS buffer` 再写入磁盘，而方式2是直接写入 `OS buffer` ，再写入磁盘，少了一次数据拷贝的过程（从 `log buffer` 到 `OS buffer` ），所以方式2比方式0更加高效。

了解了 `undo log` 和 `redo log` 的作用和实现过程之后，再来看一下这两个日志具体是怎么让数据库从异常的状态恢复到正常状态的。

数据库系统崩溃后重启，此时数据库处于**不一致**的状态，必须先执行一个 `crash recovery(崩溃恢复)` 的过程：首先读取 `redo log`，把成功提交但是还没来得及写入磁盘的数据重新写入磁盘，保证了持久性。再读取 `undo log` 将还没有成功提交的事务进行回滚，保证了原子性。`crash recovery` 结束后，数据库恢复到一致性状态，可以继续被使用。

###### **隔离性**

数据库事务的隔离性是指：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。正常情况下，肯定是多个事务同时操作同一个数据库，所以事务之间的隔离就显得必不可少。先看一下，**如果没有隔离性**，会发生的问题[脏读、丢失修改、不可重复读、幻读](#####8.2、并发事务带来哪些问题？)。

==分为**快照读**和**当前读**两种情况。==

在MySQL **可重复读** 的隔离级别下：

![image-20210808144922747](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210808144922747.png)

按照上述理论，会出现幻读现象。也就是事务A的第二次`select`会看到事务B提交的新增数据。

执行结果如下：

```mysql
mysql> select * from student;
+----+----------+
| id | name     |
+----+----------+
|  1 | zhangsan |
+----+----------+
1 row in set (0.00 sec)
```

和预期的结果并不一致，没有出现幻读现象。
实际上MySQL在`Repeatable Read`隔离级别下，用 `MVCC(Multiversion Concurrency Control，多版本并发控制)`解决了`select`普通查询的幻读现象。

具体的实现方式就是事务开始时，第一条 `select` 语句查询结果集会生成一个 `快照（snapshot）`，并且这个事务结束前，同样的 `select` 语句返回的都是这个快照的结果，而不是最新的查询结果，这就是MySQL在 `Repeatable Read` 隔离级别对普通 `select` 语句使用的**快照读``（snapshot read）``**。

**快照读**和**MVCC**是什么关系呢？

MVCC是多版本并发控制，快照就是其中的一个版本。所以可以说MVCC实现了快照读，具体的实现方式涉及到MySQL的隐藏列。MySQL会给每个表自动创建三个隐藏列。

- `DB_TRX_ID`：事务ID，记录操作（增、删、改）该数据事务的事务ID
- `DB_ROLL_PTR`：回滚指针，记录上一个版本的数据在`undo log`中的位置
- `DB_ROW_ID`：隐藏ID ，创建表没有合适的索引作为聚簇索引时，会用该隐藏ID创建聚簇索引

由于`undo log`中记录了各个版本的数据，并且通过`DB_ROLL_PTR`可以找到各个历史版本，并且由`DB_TRX_ID`决定使用哪个版本（快照）。所以相当于`undo log`实现了MVCC，MVCC实现了快照读。



**当前读**的情况：

我们发现在下面这个例子中发生了幻读：

![image-20210808145633540](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210808145633540.png)

查询结果：

```mysql
mysql> select * from student;
+----+----------+
| id | name     |
+----+----------+
|  1 | zhangsan |
|  2 | lisi     |
|  3 | zhaoliu  |
+----+----------+
3 rows in set (0.00 sec)
```

这是因为MySQL对 `insert`、`update` 和 `delete` 语句所使用的是 **当前读（`current read`）**。因为涉及到数据的修改，所以MySQL必须拿到最新的数据才能修改，所以**涉及到数据的修改肯定不能使用快照读（``snapshot read`）**。由于事务A读到了事务B已提交的新增数据，所以就产生了前文所说的幻读。

**那么在`Repeatable Read`隔离级别是怎么解决幻读的呢？**

是通过 ==Next-Key Lock== 来解决的。我们都知道 InnoDB 支持行锁，并且行锁是锁住索引。而**间隙锁**用来锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为 `Repeatable Read` 或以上级别而已的，间隙锁和行锁一起组成了 ==Next-Key Lock==。当 InnoDB 扫描索引记录的时候，会首先对索引记录加上行锁，再对索引记录两边的间隙加上间隙锁（`Gap Lock`）。加上间隙锁之后，其他事务就不能在这个间隙插入记录。这样就有效的防止了幻读的发生。

默认情况下，InnoDB工作在`Repeatable Read`的隔离级别下，并且以`Next-Key Lock`的方式对索引行进行加锁。当查询的索引具有唯一性（**主键**、**唯一索引**）时，Innodb存储引擎会对`Next-Key Lock`进行优化，将其降为**行锁**，仅仅锁住索引本身，而不是范围（除非锁定不存在的值）。若是**普通索引**，则会使用`Next-Key Lock`将记录和间隙一起锁定。

![image-20210808150824901](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210808150824901.png)

事务A在`T1`时刻执行的语句会给`id > 1`的索引和间隙加上`Next-Key Lock`，此时事务B便不能在记录2的后面插入新的数据，所以事务A在`T1`是可和`T4`时刻会查询到相同的结果集，这样就解决了**幻读**问题。

###### **一致性**

- MySQL一致性的保证是从2个方面来保证的。
  - 从数据库层面来看，**数据库通过原子性、隔离性、持久性来保证一致性**。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。
  - 因此，还必须从应用层角度考虑。从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！



##### 8.6、 日志 `binlog`、`redolog`、`undolog`

**服务层：**
==`bin log`==：DDL(数据定义语言：创建数据库和表) DML(数据操作语言:insert、update、delete)。可以用来进行数据库的恢复及复制。有三种形式:statement（记录sql语句，比如创建表、插入数据、更改数据、删除数据等操作的sql语句）、row（记录所有发生变化的行，比较大）、mixed（两种的混合）。

**引擎层(InnoDB独有)：**

1. ==`redo log`==：记录的是要更新的数据。 一条数据提交成功并不是立即写入磁盘，而是先写到redolog中，等待合适的时机再写入磁盘。 ==保证持久性==
2. ==`undo log`==：记录当前操作中的相反操作，比如一条insert语句在undolog中记录为delete。在事务回滚时会用到undolog，实现
事务的原子性。。。。而且同时会用在MVCC中，undo中会有
一条记录的多个版本，用在快照读中。 ==保证原子性==



三种日志写入的时间：
1. 一个事务刚开始时，为了防止事务回滚，要先写入`undo log`（只有写入了`undo log`）才有可能实现回滚。
2. 在写入`undo log`后，要写入`redo log`，这里指的是 `redo log buffer` ，而不是 `redo log file`，至于何时写入磁盘有一个配置参数来决定
3. 写入 `redo log` 后，事务会处于` prepare` 状态，告诉执行器随时可以提交事务，执行器便会生成 `bin log` 日志并写入磁盘，调用 `innodb` 事务提交接口，进行事务提交，`prepare` 状态的 redo log 也会进入 commit 状态。

![image-20210807215943148](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210807215943148.png)

###### redo log为什么有 prepare 状态，不直接提交？

如果直接提交，没有 `prepare` 状态：
（1）`redo log` 直接提交，然后再写 `bin log`：如果在提交后，机器挂了，`bin log` 没有写入，那么重启的时候，可以通过 `redo log` 恢复数据，但是 `bin log` 中没有记录该数据，后续备份时会丢失该数据，主从同步也会丢失；

（2）先写 `bin log` 再写 `redo log` ：如果写完 `bin log` 后及其异常重启了，由于没有 `redo log`，本机不能恢复该数据，但是 `bin log` 有，会导致数据不一致

如果 `redo log` 分两阶段提交，写完 `binlog` 再提交，两个日志中的信息就会同步，会防止数据的不一致性。如果出现 `redo log` 处于 `prepare` 状态时，` bin log` 也写完了，但是此时异常重启了，MySQL处理过程：

如果 `redolog` 只是出于预提交状态而不是commit，就会去判断 `binlog` 是否完整，如果完整就提交 `redo log` ，否则就回滚。

*********************

#### 9、锁机制与InnoDB锁算法

**MyISAM和InnoDB存储引擎使用的锁：**

- MyISM采用表级锁(table-level locking)。
- InnoDB采用行级锁(row-level lock)和表级锁，默认是行级锁。

###### 表级锁和行级锁对比：

- **表级锁：**MySQL中锁定**粒度最大**的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和InnoDB引擎都支持表级锁。
- **行级锁：**MySQL中锁定**粒度最小**的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

###### InnoDB存储引擎的锁的算法有三种

- Record lock：单个行记录的锁；
- Gap lock：间隙锁，锁定一个范围，不包括记录本身；
- Next-key lock：record+gap锁定一个范围，包括记录本身。

相关知识点：

1. innodb对于行的查询使用next-key lock
2. Next-locking keying为了解决Phantom Problem幻读问题
3. 当查询的索引含有唯一属性时，将next-key lock降级为record key4.Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
4. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）A.将事务隔离级别设置为RCB.将参数innodb_locks_unsafe_for_binlog设置为1

##### [MySQL锁机制详解](https://www.cnblogs.com/volcano-liu/p/9890832.html)

总的来说，`InnoDB` 共有七种类型的锁：

- 共享/排它锁(Shared and Exclusive Locks)
- 意向锁(Intention Locks)
- 记录锁(Record Locks)
- 间隙锁(Gap Locks)
- 临键锁(Next-key Locks)
- 插入意向锁(Insert Intention Locks)
- 自增锁(Auto-inc Locks)

**共享/排它锁(Shared and Exclusive Locks)**

- 共享锁（Share Locks，记为S锁），读取数据时加S锁
- 排他锁（eXclusive Locks，记为X锁），修改数据时加X锁

使用的语义为：

- 共享锁之间不互斥，简记为：读读可以并行
- 排他锁与任何锁互斥，简记为：写读，写写不可以并行

　　可以看到，一旦写数据的任务没有完成，数据是不能被其他任务读取的，这对并发度有较大的影响。对应到数据库，可以理解为，写事务没有提交，读相关数据的select也会被阻塞，这里的select是指加了锁的，普通的select仍然可以读到数据(快照读)。

**意向锁(Intention Locks)**

`InnoDB` 为了支持多粒度锁机制(multiple granularity locking)，即允许行级锁与表级锁共存，而引入了意向锁(intention locks)。意向锁是指，未来的某个时刻，事务可能要加 共享/排它锁 了，先提前声明一个意向。

1. 意向锁是一个表级别的锁(table-level locking)；
2. 意向锁又分为：
   - 意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁；
   - 意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁；

　　加锁的语法为：

```mysql
select ... lock in share mode;　　要设置IS锁；
select ... for update;　　　　　　 要设置IX锁；
```

事务要获得某些行的S/X锁，必须先获得表对应的IS/IX锁，意向锁仅仅表明意向，意向锁之间相互兼容，兼容互斥表如下：

|        | IS    | IX    |
| ------ | ----- | ----- |
| **IS** | 兼 容 | 兼 容 |
| **IX** | 兼 容 | 兼 容 |

虽然意向锁之间互相兼容，但是它与共享锁/排它锁互斥，其兼容互斥表如下:

|        | S     | X     |
| ------ | ----- | ----- |
| **IS** | 兼 容 | 互 斥 |
| **IX** | 互 斥 | 互 斥 |

排它锁是很强的锁，不与其他类型的锁兼容。这其实很好理解，修改和删除某一行的时候，必须获得强锁，禁止这一行上的其他并发，以保障数据的一致性。

**记录锁(Record Locks)**

记录锁，它封锁索引记录，例如(其中id为pk)：

```mysql
create table lock_example(id smallint(10),name varchar(20),primary key id)engine=innodb;
```

数据库隔离级别为RR，表中有如下数据：

```mysql
10, zhangsan
20, lisi
30, wangwu
select * from t where id=1 for update;
```

其实这里是先获取该表的意向排他锁(IX)，再获取这行记录的排他锁(我的理解是因为这里直接命中索引了)，以阻止其他事务插入，更新，删除id=1的这一行。

**间隙锁(Gap Locks)**

间隙锁，它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。依然是上面的例子，InnoDB，RR：

```mysql
select * from lock_example
where id between 8 and 15 
for update;
```

这个SQL语句会封锁区间(8,15)，以阻止其他事务插入id位于该区间的记录。

　　间隙锁的主要目的，就是为了防止其他事务在间隔中插入数据，以导致“不可重复读”。**如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。**



**临键锁(Next-key Locks)**

临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。

默认情况下，innodb使用next-key locks来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。

举个例子，依然是如上的表lock_example，但是id降级为普通索引(key)，也就是说即使这里声明了要加锁(for update)，而且命中的是索引，但是因为索引在这里没有UK约束，所以innodb会使用next-key locks，数据库隔离级别RR：

```mysql
事务A执行如下语句，未提交：
select * from lock_example where id = 20 for update;

事务B开始，执行如下语句，会阻塞：
insert into lock_example values('zhang',15);
```

如上的例子，事务A执行查询语句之后，默认给id=20这条记录加上了next-key lock，所以事务B插入10(包括)到30(不包括)之间的记录都会阻塞。临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别**降级为RC，临键锁则也会失效**。

**插入意向锁(Insert Intention Locks)**

对已有数据行的修改与删除，必须加强互斥锁(X锁)，那么对于数据的插入，是否还需要加这么强的锁，来实施互斥呢？插入意向锁，孕育而生。

　　插入意向锁，是间隙锁(Gap Locks)的一种（所以，也是实施在索引上的），它是专门针对insert操作的。多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。

举个例子(表依然是如上的例子lock_example，数据依然是如上)，事务A先执行，在10与20两条记录中插入了一行，还未提交：

```mysql
insert into t values(11, xxx);
```

事务B后执行，也在10与20两条记录中插入了一行：

```mysql
insert into t values(12, ooo);
```

因为是插入操作，虽然是插入同一个区间，但是插入的记录并不冲突，所以使用的是插入意向锁，此处A事务并不会阻塞B事务。

**自增锁(Auto-inc Locks)**

自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。

举个例子(表依然是如上的例子lock_example)，但是id为AUTO_INCREMENT，数据库表中数据为：

```mysql
1, zhangsan
2, lisi
3, wangwu
```

　　事务A先执行，还未提交： insert into t(name) values(xxx);

　　事务B后执行： insert into t(name) values(ooo);

　　此时事务B插入操作会阻塞，直到事务A提交。

**总结**

以上总结的7种锁，个人理解可以按两种方式来区分：

　　**1. 按锁的互斥程度来划分，可以分为共享、排他锁；**

- 共享锁(S锁、IS锁)，可以提高读读并发；

- 为了保证数据强一致，InnoDB使用强互斥锁(X锁、IX锁)，保证同一行记录修改与删除的串行性；

　　**2. 按锁的粒度来划分，可以分为：**

- 表锁：意向锁(IS锁、IX锁)、自增锁；

- 行锁：记录锁、间隙锁、临键锁、插入意向锁；

　　其中

1. `InnoDB` 的细粒度锁(即行锁)，是实现在索引记录上的(我的理解是如果未命中索引则会失效)；　　
2. 记录锁锁定索引记录；间隙锁锁定间隔，防止间隔中被其他事务插入；临键锁锁定索引记录+间隔，防止幻读；
3. `InnoDB` 使用插入意向锁，可以提高插入并发；
4. 间隙锁(gap lock)与临键锁(next-key lock)**只在RR以上的级别生效，RC下会失效**；

*************

#### MySQL慢查询

###### **概念：**

​		`MySQL` 的慢查询日志是 `MySQL `提供的一种日志记录，它用来记录在 `MySQL `中响应时间超过阀值的语句，具体指运行时间超过 `long_query_time` 值的SQL，则会被记录到**慢查询日志**中。`long_query_time`的默认值为 `10`，意思是运行`10S` 以上的语句。默认情况下，`MySQL` 数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。

###### **相关参数：**

```markdown
- `slow_query_log`：是否开启慢查询日志，1表示开启，0表示关闭。

- `log-slow-queries`：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件 `host_name-slow.log`

- `slow-query-log-file`：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件 `host_name-slow.log`

- `long_query_time`：慢查询阈值，当查询时间多于设定的阈值时，记录日志。

- `log_queries_not_using_indexes`：未使用索引的查询也被记录到慢查询日志中（可选项）。

- `log_output`：日志存储方式。log_output='FILE'表示将日志存入文件，默认值是'FILE'。log_output='TABLE'表示将日志存入数据库。
```

###### **慢查询定位的方式**

- 根据慢查询日志定位；
- 使用 `show processlist` 定位，查询正在执行的慢查询。

> 根据慢查询日志定位

​	`MySQL `的慢查询日志记录的内容是：在 `MySQL `中响应时间超过参数` long_query_time`（单位秒，默认值 10）设置的值并且扫描记录数不小于 `min_examined_row_limit`（默认值0）的语句。

```mysql
# 开启慢查询日志
mysql> set global slow_query_log = on;

# 设置慢查询时间限制（查询时间只要大于这个值都将记录到慢查询日志中，单位：秒)
mysql> set global long_query_time = 1;

# 确定慢查询日志路径
mysql> show global variables like "datadir";

# 确定慢查询日志文件名
mysql> show global variables like "slow_query_log_file";

#接下来在确定慢查询日志后可以通过：
tail -n5 /data/mysql/mysql-slow.log 命令查看

# 执行结果：
tail -n5：只查看慢查询文件的最后5行
Time：慢查询发生的时间
User@Host：客户端用户和IP
Query_time：查询时间
Lock_time：等待表锁的时间
Rows_sent：语句返回的行数
Rows_examined：语句执行期间从存储引擎扫描的行数
```

> **通过` show processlist`定位慢查询**

​		有时慢查询正在执行，已经导致数据库负载偏高了，而由于慢查询还没执行完，因此慢查询日志还看不到任何语句。此时可以使用 `show processlist` 命令判断正在执行的慢查询。`show processlist` 显示哪些线程正在运行。如果有 `PROCESS  `权限，则可以看到所有线程。否则，只能看到当前会话的线程。

如果不使用 FULL 关键字，在 info 字段中只显示每个语句的前 100 个字符，如果想看语句的全部内容可以使用 `full `修饰（`show full processlist`）。

![img](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/d0c8a786c9177f3e4e4cf989811449c29e3d561e.jpeg)

这里对上面结果重点参数解释一下：

Time：表示执行时间

Info：表示 SQL 语句我们这里可以通过它的执行时间（Time）来判断是否是慢 SQL。

###### 优化慢查询的方法

```markdown
1. 查询如果慢的建立索引可以提升速度
	相当于就是之前一个表数据量比较小，之后数据量大了查询就变慢，此时在经常用到的字段上加个索引，效率会翻倍很多
2. 建立索引是为了提升速度，所以避免对索引字段进行计算或类型转化
	where a * 5 = 10 可以 转化为 where a = 10/5 
3. 表的设计尤为重要，避免使用LEFT JOIN 或 RIGHT JOIN去联表查询
4. 查询字段时不要全部返回，忌讳使用\*，最好是用什么字段返回什么地段，也可使得相关业务更加清晰
5. 有些情况对字段的使用比较特殊，建议去建议表达式索引去提供效率
6. 部分索引其实差不多是联合索引，几个字段查询的值一直都是常量，此时就可以考虑部分索引.
```





************

#### 大表优化

当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

###### **限定数据的范围**

务必禁止不带任何限制数据范围条件的查询语句。比如：我们在查询订单历史的时候，我们可以控制在一个月的范围内。

###### **读写分离**

经典的数据库拆分方案，主库负责写，从库负责读；

> 读写分离要考虑的问题
>
> - 数据库连接池要进行区分，哪些是读连接池，哪个是写连接池，研发的难度会增加；
> - 为了保证高可用，读连接池要能够实现故障自动转移；
> - 主从的一致性问题需要考虑。
>
> > 缓存，也是互联网中常常使用到的一种架构方式，同“读写分离”不同，读写分离是通过多个读库，分摊了数据库读的压力，而存储则是通过缓存的使用，减少了数据库读的压力。他们没有谁替代谁的说法，但是，如果在缓存的读写分离进行二选一时，还是应该首先考虑缓存。
> >
> > 因为缓存的使用成本要比从库少非常多；缓存的开发比较容易，大部分的读操作都可以先去缓存，找不到的再渗透到数据库。
> >
> > 如果我们已经运用了缓存，但是读依旧还是瓶颈时，就可以选择“读写分离”。

###### 垂直分区

​		**根据数据库里面数据表的相关性进行拆分。**例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

​		**简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。**如下图所示，这样来说大家应该就更容易理解了。

![image-20210412105802272](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412105802272.png)

- **垂直拆分的优点：**可以使得列数据变小，在查询时减少读取的Block数，减少/0次数。此外，垂直分区可以简化表的结构，易于维护。
- **垂直拆分的缺点：**主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

###### 水平分区

**保持数据表结构不变，通过某种策略存储数据分⽚。这样每⼀⽚数据分散到不同的表或者库中，达到了分布式的⽬的。 ⽔平拆分可以⽀撑⾮常⼤的数据量。**

​		水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

![image-20210412110004699](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412110004699.png)

水平拆分可以支持非常大的数据量。需要注意的一点是：**分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库。**

水平拆分能够**支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，**跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐**尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度，**一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络/O。

**下面补充一下数据库分片的两种常见方案：**

- **客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。当当网的Sharding-JDBC、阿里的TDDL是两种比较常用的实现。**
- **中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。**我们现在谈的Mycat、360的Atlas、网易的DDB等等都是这种架构的实现。

#### 解释一下池化操作设计思想。什么是数据库连接池？为什么需要数据库连接池？

​		池化设计应该不是一个新名词。我们常见的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。**这种设计会初始预设资源**，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。就好比你去食堂打饭，打饭的大妈会先把饭盛好几份放那里，你来了就直接拿着饭盒加菜即可，不用再临时又盛饭又打菜，效率就高了。除了初始化资源，**池化设计还包括如下这些特征：池子的初始值、池子的活跃值、池子的最大值等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。**

​		数据库连接本质就是一个socket的连接。数据库服务端还要维护一些缓存和用户权限信息之类的，所以占用了一些内存。我们可以把数据库连接池是看做是维护的数库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。**在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。**连接池还减少了用户必须等待建立与数据库的连接的时间。

#### 分库分表以后，id主键如何处理？

如果分成多个表以后，每个表都是从1开始累加，这样是不对的，**我们需要一个全局唯一的id来支持。**

##### 生成全局id的方式

- **UUID：**不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
- **数据库自增id：**两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的id有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。
- **利用 `redis` 生成id：**性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。
- **Twitter的snowflake算法：**Github 地址：hfhtos/techmeituanconm/2017/04/21/mt]/snowflake。
- **美团的Leaf分布式ID生成系统**：Leaf 是美eaf.html全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。

##### 自增ID

自增ID是在设计表时将id字段的值设置为自增的形式，这样当插入一行数据时无需指定id会自动根据前一字段的ID值+1进行填充。在MySQL数据库中，可通过 `sql` 语句 `AUTO_INCREMENT` 来对特定的字段启用自增赋值 使用自增ID作为主键，能够保证字段的原子性。

**优点：**

- 数据库自动编号，速度快，而且是增量增长，按顺序存放，对于检索非常有利；
- 数字型，占用空间小，易排序，在程序中传递也方便；
- 如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题。

**缺点：**

- 因为自动增长，在手动要插入指定ID的记录时会显得麻烦，尤其是当系统与其它系统集成时，需要数据导入时，很难保证原系统的ID不发生主键冲突（前提是老系统也是数字型的）。特别是在新系统上线时，新旧系统并行存在，并且是异库异构的数据库的情况下，需要双向同步时，自增主键将是你的噩梦；
- 在系统集成或割接时，如果新旧系统主键不同是数字型就会导致修改主键数据类型，这也会导致其它有外键关联的表的修改，后果同样很严重；
- 若系统也是数字型的，在导入时，为了区分新老数据，可能想在老数据主键前统一加一个字符标识（例如“o”，old）来表示这是老数据，那么自动增长的数字型又面临一个挑战

##### UUID

UUID含义是通用唯一识别码 (Universally Unique Identifier)，指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。通常平台会提供生成的API。换句话说能够在一定的范围内保证主键id的唯一性。

**优点**：

出现数据拆分、合并存储的时候，能达到全局的唯一性。

**缺点：**

- 影响插入速度， 并且造成硬盘使用率低
- uuid太长，相对数字慢不少， 影响查询速度。
- uuid占空间大， 如果建的索引越多， 影响越严重

*******

#### 一条SQL语句在MySQL中如何执行

在分析之前先看看 MySQL 的基础架构，知道了 MySQL 由那些组件组成以及这些组件的作用是什么，可以帮助我们理解和解决这些问题。

#####  MySQL 基础架构分析

###### MySQL 基本架构概览

下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。

先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。

•**连接器：** 身份认证和权限相关(登录 MySQL 的时候)。

•**查询缓存:** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

•**分析器:** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。

•**优化器：** 按照 MySQL 认为最优的方案去执行。

•**执行器:** 执行语句，然后从存储引擎返回数据。

![640](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/640.png)

简单来说 MySQL 主要分为 Server 层和存储引擎层：

•**Server 层**：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。

•**存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。**

###### Server 层基本组件介绍

> 1) 连接器
>
> 连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。
>
> 主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。

>  2) 查询缓存(MySQL 8.0 版本后移除)
>
> 查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。
>
> 连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。
>
> MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。
>
> 所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。
>
> MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。

>  3) 分析器
>
> MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：
>
> **第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。
>
> **第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。
>
> 完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。

>  4) 优化器
>
> 优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。
>
> 可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。

>  5) 执行器
>
> 当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。

##### 语句分析

> **查询语句**
>
> 说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下：

```mysql
select * from tb_student A where A.age='18' and A.name=' 张三 ';
```

**结合上面的说明，我们分析下这个语句的执行流程：**

- 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。
- 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
- 接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案：

```mysql
  a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。 
  b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。
```

​    那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。

- 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

>  **更新语句**
>
> 以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下：

```mysql
update tb_student A set A.age='19' where A.name=' 张三 ';
```

我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式 **binlog（归档日志）** ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 **redo log（重做日志）**，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：

•先查询到张三这一条数据，如果有缓存，也是会用到缓存。•然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。•执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。•更新完成。

**这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗?**

这是因为最开始 MySQL 并没与 InnoDB 引擎( InnoDB 引擎是其他公司以插件形式插入 MySQL 的) ，MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。

并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？

•**先写 redo log 直接提交，然后写 binlog**，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。•**先写 binlog，然后写 redo log**，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。

如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：

•判断 redo log 是否完整，如果判断是完整的，就立即提交。•如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。

这样就解决了数据一致性的问题。



#### SQL优化

- 对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
- 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。

```mysql
select id from t where num is null    
```

可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：    

```mysql
select id from t where num=0  
```

- 应尽量避免在 where 子句中使用 != 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描。
- 应尽量避免在 where 子句中使用 or 来连接条件，==如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描==，如：

```mysql
select id from t where num=10 or Name = 'admin'
```

可以这样查询：

```mysql
select id from t where num = 10
union all
select id from t where Name = 'admin'
```

- in 和 not in 也要慎用，否则会导致全表扫描，如：

  ```mysql
  select id from t where num in (1,2,3)
  ```

  对于连续的数值，能用 between 就不要用 in 了：

  ```mysql
  select id from t where num between 1 and 3
  ```

  很多时候用 exists 代替 in 是一个好的选择：

  ```mysql
  select num from a where num in (select num from b)
  ```

  用下面的语句替换：

  ```mysql
  select num from a where exists(select 1 from b where num=a.num)
  ```

- 下面的查询也将导致全表扫描：

  ```mysql
  select id from t where name like ‘%abc%’
  ```

  若要提高效率，可以考虑全文检索

具体可见[SQL优化](https://www.cnblogs.com/yunfeifei/p/3850440.html)

#### 一条SQL语句执行得很慢的原因有哪些

一条 SQL 语句执行的很慢，那是每次执行都很慢呢？还是大多数情况下是正常的，偶尔出现很慢呢？所以我觉得，我们还得分以下两种情况来讨论。

**1、大多数情况是正常的，只是偶尔会出现很慢的情况。**

**2、在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。**

##### 针对偶尔很慢的情况

> 一条 SQL 大多数情况正常，偶尔才能出现很慢的情况，针对这种情况，我觉得这条SQL语句的书写本身是没什么问题的，而是其他原因导致的。

###### 数据库在刷新脏页（flush）

当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到**磁盘**中去。

> 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

**刷脏页有下面4种场景（后两种不用太关注“性能”问题）：**

- **redo log写满了：**redo log 里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，**就会导致我们平时正常的SQL语句突然执行的很慢**，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。
- **内存不够用了：**如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。
- **MySQL 认为系统“空闲”的时候：**这时系统没什么压力。
- **MySQL 正常关闭的时候：**这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快

###### 拿不到锁

这个就比较容易想到了，我们要执行的这条语句，刚好这条语句涉及到的**表**，别人在用，并且加锁了，我们拿不到锁，只能慢慢等待别人释放锁了。或者，表没有加锁，但要使用到的某一行被加锁了，这个时候，我也没办法啊。

如果要判断是否真的在等待锁，我们可以用 **`show processlist`** 这个命令来查看当前的状态哦，这里我要提醒一下，有些命令最好记录一下，反正，我被问了好几个命令，都不知道怎么写，呵呵。

下来我们来访分析下第二种情况，我觉得第二种情况的分析才是最重要的

##### 针对一直都这么慢的情况

> 如果在数据量一样大的情况下，这条 SQL 语句每次都执行的这么慢，那就就要好好考虑下你的 SQL 书写了，下面我们来分析下哪些原因会导致我们的 SQL 语句执行的很不理想。

我们先来假设我们有一个表，表里有下面两个字段,分别是主键 id，和两个普通字段 c 和 d。

![image-20210412113540964](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412113540964.png)

###### 1. 没用到索引

没有用上索引，我觉得这个原因是很多人都能想到的，例如你要查询这条语句

![image-20210412113609396](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412113609396.png)

- **字段没有索引**  刚好你的 c 字段上没有索引，那么抱歉，只能走全表扫描了，你就体验不会索引带来的乐趣了，所以，这回导致这条查询语句很慢。

- **字段有索引，但却没有用索引**  给 c 这个字段加上了索引，然后又查询了一条语句![image-20210412113716895](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412113716895.png)如果我们在字段的左边做了运算，那么很抱歉，在查询的时候，就不会用上索引了，所以呢，大家要注意这种**字段上有索引，但由于自己的疏忽，导致系统没有使用索引**的情况了。![image-20210412113749521](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412113749521.png)

- **函数操作导致没有用上索引**  如果我们在查询的时候，对字段进行了函数操作，也是会导致没有用上索引的，例如![image-20210412113855948](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412113855948.png)这里我只是做一个例子，假设函数 pow 是求 c 的 n 次方，实际上可能并没有 pow(c,2)这个函数。其实这个和上面在左边做运算也是很类似的。

  所以呢，一条语句执行都很慢的时候，可能是该语句没有用上索引了，不过具体是啥原因导致没有用上索引的呢，你就要会分析了，我上面列举的三个原因，应该是出现的比较多的吧。

###### 2. 数据库自己选错索引了

我们在进行查询操作的时候，例如![image-20210412114013738](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412114013738.png)

主键索引和非主键索引是有区别的，主键索引存放的值是**整行字段的数据**，而非主键索引上存放的值不是整行字段的数据，而且存放**主键字段的值**。

我们如果走 c 这个字段的索引的话，最后会查询到对应主键的值，然后，再根据主键的值走主键索引，查询到整行数据返回。

好吧扯了这么多，其实我就是想告诉你，就算你在 c 字段上有索引，系统也并不一定会走 c 这个字段上的索引，而是有可能会直接扫描扫描全表，找出所有符合 100 < c and c < 100000 的数据。

**为什么会这样呢？**

其实是这样的，系统在执行这条语句的时候，会进行预测：究竟是走 c 索引扫描的行数少，还是直接扫描全表扫描的行数少呢？显然，扫描行数越少当然越好了，因为扫描行数越少，意味着I/O操作的次数越少。

如果是扫描全表的话，那么扫描的次数就是这个表的总行数了，假设为 n；而如果走索引 c 的话，我们通过索引 c 找到主键之后，还得再通过主键索引来找我们整行的数据，也就是说，需要走两次索引。而且，我们也不知道符合 $100 <c $and $c < 10000$ 这个条件的数据有多少行，万一这个表是全部数据都符合呢？这个时候意味着，走 c 索引不仅扫描的行数是 n，同时还得每行数据走两次索引。

**所以呢，系统是有可能走全表扫描而不走索引的。那系统是怎么判断呢？**

判断来源于系统的预测，也就是说，如果要走 c 字段索引的话，系统会预测走 c 字段索引大概需要扫描多少行。如果预测到要扫描的行数很多，它可能就不走索引而直接扫描全表了。

那么问题来了，**系统是怎么预测判断的呢？**这里我给你讲下系统是怎么判断的吧，虽然这个时候我已经写到脖子有点酸了。

系统是通过**索引的区分度**来判断的，一个索引上不同的值越多，意味着出现相同数值的索引越少，意味着索引的区分度越高。我们也把区分度称之为**基数**，即区分度越高，基数越大。所以呢，基数越大，意味着符合 100 < c and c < 10000 这个条件的行数越少。

所以呢，一个索引的基数越大，意味着走索引查询越有优势。

**那么问题来了，怎么知道这个索引的基数呢？**

系统当然是不会遍历全部来获得一个索引的基数的，代价太大了，索引系统是通过遍历部分数据，也就是通过**采样**的方式，来预测索引的基数的。

**扯了这么多，重点的来了**，居然是采样，那就有可能出现**失误**的情况，也就是说，c 这个索引的基数实际上是很大的，但是采样的时候，却很不幸，把这个索引的基数预测成很小。例如你采样的那一部分数据刚好基数很小，然后就误以为索引的基数很小。**然后就呵呵，系统就不走 c 索引了，直接走全部扫描了**。

所以呢，说了这么多，得出结论：**由于统计的失误，导致系统没有走索引，而是走了全表扫描**，而这，也是导致我们 SQL 语句执行的很慢的原因。

> 这里我声明一下，系统判断是否走索引，扫描行数的预测其实只是原因之一，这条查询语句是否需要使用使用临时表、是否需要排序等也是会影响系统的选择的。

不过呢，我们有时候也可以通过强制走索引的方式来查询，例如

```mysql
select * from t force index(a) where c < 100 and c < 100000;
```

我们也可以通过

```mysql
show index from t;
```

来查询索引的基数和实际是否符合，如果和实际很不符合的话，我们可以重新来统计索引的基数，可以用这条命令

```mysql
analyze table t;
```

来重新统计分析。

**既然会预测错索引的基数，这也意味着，当我们的查询语句有多个索引的时候，系统有可能也会选错索引哦**，这也可能是 SQL 执行的很慢的一个原因。

好吧，就先扯这么多了，你到时候能扯出这么多，我觉得已经很棒了，下面做一个总结。

![image-20210412114234076](https://gitee.com/yun-xiaojie/blog-image/raw/master/img/image-20210412114234076.png)

#### Redis

> **Redis是一个使用C语言开发的数据库**，不过与传统数据库不同的是，**Redis的数据是存在内存中的**，也就是它是内存数据库，多以读写速度很快。
>
> **Redis除了做缓存之外，Redis也经常用来做分布式锁，甚至是消息队列。**
>
> **Redis 提供了多种数据类型来⽀持不同的业务场景。Redis 还⽀持事务 、持久化、Lua 脚本、多
> 种集群⽅案。**

具体见[Redis.md](Redis.md)。

#### 如何保证缓存和数据库数据的一致性

引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。

下面单独对**Cache Aside Pattern（旁路缓存模式）**来聊聊。

Cache Aside Pattern 中遇到写请求是这样的：更新DB，然后直接删除cache。

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

1. **缓存失效时间变短（不推荐，治标不治本）：**我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
2. **增加cache更新重试机制（常用）：**如果cache服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的key存入队列中，等缓存服务可用之后，再将缓存中对应的key 删除即可。



#### SQL 语句

##### [Union与Union All的区别](https://www.cnblogs.com/wcl2017/p/7078685.html)

如果我们需要将两个select语句的结果作为一个整体显示出来，我们就需要用到union或者union all关键字。

union(或称为联合)的作用是将多个结果合并在一起显示出来。

**union和union all的区别是**

> union会自动压缩多个结果集合中的重复结果，而union all则将所有的结果全部显示出来，不管是不是重复。
>
> > Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；
> >
> > Union All：对两个结果集进行并集操作，包括重复行，不进行排序；

##### 数据库聚合函数

###### count 

> 统计一共有多少条记录
>
> ```mysql
> select count(id) from students;
> ```

###### sum

> 用来计算和
>
> ```mysql
> select sum(score) from students;
> ```

###### max 

> 用来求最大值
>
> ```my
> select max(score) from students
> ```

###### min

> 求最小值
>
> ```mysql
> select min(score) from students
> ```

###### avg

> 求平均值
>
> ```mysql
> select avg(score) from students;
> ```

##### [drop、truncate和delete的区别](https://www.cnblogs.com/jiezao/p/13637099.html)

1. DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。
2. DELETE操作不会减少表或索引所占用的空间，TRUNCATE这个表和索引所占用的空间会恢复到初始大小，drop语句将表所占用的空间全释放掉。
3. TRUNCATE 只能对TABLE；DELETE可以是table和view
4. TRUNCATE 和DELETE只删除数据， DROP则删除整个表（结构和数据）。
5. delete语句为DML,这个操作会被放到 rollback segment中, 事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。truncate、drop是DLL,操作立即生效，原数据不放到 rollback segment中，不能回滚。
6. 一般而言，速度drop > truncate > delete。

##### 创建索引

```mysql
CREATE [UNIQUE|CLUSTERED] INDEX INDEX_NAME ON TABLE_NAME(PROPERTY_NAME)
# UNIQUE和CLUSTERED为可选项，分别是建立唯一索引和聚簇索引
# UNIQUE:表示此索引的每一个索引值只对应唯一的数据。
# CLUSTERED:表示要建立的索引时聚簇索引，即索引项的顺序与表中记录的物理顺序一致的索引组织。
```



######  COUNT(1)、COUNT(列名)、COUNT(*)的区别

- `count(*)` 包括了所有的列，相当于行数，在统计结果的时候，会统计值为NULL的；
- `count(1)` 包括了所有的列，**把值全部换成1再计数**，在统计结果的时候，会统计值为NULL的；
- `count(列名)` 只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

执行效率上：  

- `COUNT(字段)`多了一个步骤就是判断所查询的字段是否为NULL，所以他的性能要比`COUNT(*)`慢。
- 列名为主键，count(列名)会比count(1)快  
- 列名不为主键，count(1)会比count(列名)快  
- 如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*）
- 如果有主键，则 select count（主键）的执行效率是最优的
- 如果表只有一个字段，则 select count（*）最优。

